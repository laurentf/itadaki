{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🍜 Itadaki - Recipe Image Retrieval (Fine-Tuning)\n",
        "\n",
        "_\"Fine-tuning EfficientNet with 20 unfrozen layers for optimal recipe similarity\"_\n",
        "\n",
        "## 🎯 Overview\n",
        "\n",
        "**Fine-Tuning Strategy:**\n",
        "- 🧊 **Frozen layers:** EfficientNetB0 layers 0-215 (feature extraction)\n",
        "- 🔥 **Unfrozen layers:** Last 20 layers + custom head (fine-tuning)\n",
        "- 🎛️ **Learning rates:** Very low LR for unfrozen layers (0.0001)\n",
        "- 📈 **Training:** Triplet loss with hard negative mining\n",
        "\n",
        "**Expected improvements over Transfer Learning:**\n",
        "- Better feature adaptation to food images\n",
        "- Higher similarity accuracy\n",
        "- More robust embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔥 FINE-TUNING CONFIGURATION\n",
            "==================================================\n",
            "📐 Image Size: 224x224\n",
            "📦 Batch Size: 16\n",
            "🔥 Unfrozen Layers: 20\n",
            "🔄 Max Epochs: 25\n",
            "📈 Fine-tune LR: 5e-05\n",
            "🎯 Head LR: 0.001\n",
            "💧 Dropout: 0.4\n",
            "⚖️ Weight Decay: 0.0001\n",
            "⏰ Early Stopping: 5 epochs\n",
            "📉 Reduce LR: patience=3, factor=0.5\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# 🔧 FINE-TUNING CONFIGURATION\n",
        "# ============================================================================\n",
        "# 🎯 Optimized for fine-tuning with 20 unfrozen layers\n",
        "# 🔥 Lower learning rates and more epochs for stable convergence\n",
        "\n",
        "CONFIG_FT = {\n",
        "    # === ARCHITECTURE ===\n",
        "    'IMG_SIZE': 224,                    # ✅ Optimal pour EfficientNet\n",
        "    'BATCH_SIZE': 16,                   # 🔄 Reduced for fine-tuning stability\n",
        "    'EMBEDDING_DIM_CUSTOM': 512,        # ✅ Rich embeddings\n",
        "    'UNFROZEN_LAYERS': 20,              # 🆕 Number of layers to unfreeze\n",
        "    \n",
        "    # === TRAINING HYPERPARAMETERS ===\n",
        "    'FINETUNE_EPOCHS': 25,              # 🆕 More epochs for fine-tuning\n",
        "    'FINETUNE_LR': 0.00005,             # 🆕 Very low LR for fine-tuning\n",
        "    'HEAD_LR': 0.001,                   # 🆕 Higher LR for new head layers\n",
        "    \n",
        "    # === REGULARIZATION ===\n",
        "    'DROPOUT_RATE': 0.4,                # 🔄 Higher dropout for fine-tuning\n",
        "    'WEIGHT_DECAY': 0.0001,             # ✅ L2 regularization\n",
        "    'LABEL_SMOOTHING': 0.1,             # 🆕 Label smoothing for stability\n",
        "    \n",
        "    # === DATA AUGMENTATION ===\n",
        "    'USE_AUGMENTATION': True,           # ✅ Data augmentation\n",
        "    'VALIDATION_SPLIT': 0.2,           # ✅ Train/val split\n",
        "    \n",
        "    # === TRAINING CONTROL ===\n",
        "    'PATIENCE': 5,                      # 🆕 Early stopping patience\n",
        "    'REDUCE_LR_PATIENCE': 3,           # 🆕 LR reduction patience\n",
        "    'REDUCE_LR_FACTOR': 0.5,           # 🆕 LR reduction factor\n",
        "    'MIN_LR': 1e-7,                    # 🆕 Minimum learning rate\n",
        "    \n",
        "    # === MODEL SAVING ===\n",
        "    'MODEL_NAME': 'recipe_image_retrieval_model_ft.keras',\n",
        "    'CHECKPOINT_DIR': './ft/',          # 🆕 Fine-tuning model directory\n",
        "    \n",
        "    # === TRIPLET LOSS ===\n",
        "    'MARGIN': 0.2,                     # ✅ Triplet loss margin\n",
        "    'HARD_NEGATIVE_MINING': True,      # 🆕 Use hard negative mining\n",
        "}\n",
        "\n",
        "# Créer le dossier de sauvegarde\n",
        "import os\n",
        "os.makedirs(CONFIG_FT['CHECKPOINT_DIR'], exist_ok=True)\n",
        "\n",
        "print(\"🔥 FINE-TUNING CONFIGURATION\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"📐 Image Size: {CONFIG_FT['IMG_SIZE']}x{CONFIG_FT['IMG_SIZE']}\")\n",
        "print(f\"📦 Batch Size: {CONFIG_FT['BATCH_SIZE']}\")\n",
        "print(f\"🔥 Unfrozen Layers: {CONFIG_FT['UNFROZEN_LAYERS']}\")\n",
        "print(f\"🔄 Max Epochs: {CONFIG_FT['FINETUNE_EPOCHS']}\")\n",
        "print(f\"📈 Fine-tune LR: {CONFIG_FT['FINETUNE_LR']}\")\n",
        "print(f\"🎯 Head LR: {CONFIG_FT['HEAD_LR']}\")\n",
        "print(f\"💧 Dropout: {CONFIG_FT['DROPOUT_RATE']}\")\n",
        "print(f\"⚖️ Weight Decay: {CONFIG_FT['WEIGHT_DECAY']}\")\n",
        "print(f\"⏰ Early Stopping: {CONFIG_FT['PATIENCE']} epochs\")\n",
        "print(f\"📉 Reduce LR: patience={CONFIG_FT['REDUCE_LR_PATIENCE']}, factor={CONFIG_FT['REDUCE_LR_FACTOR']}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🖥️ GPU Configuration:\n",
            "⚠️ No GPU detected, using CPU\n",
            "🔢 TensorFlow version: 2.19.0\n",
            "🎲 Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# 📚 IMPORTS ET CONFIGURATION GPU\n",
        "# ============================================================================\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, GlobalAveragePooling2D, \n",
        "    Layer, Lambda, BatchNormalization\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,\n",
        "    LearningRateScheduler\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import kagglehub\n",
        "\n",
        "# Configuration GPU\n",
        "print(\"🖥️ GPU Configuration:\")\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"✅ {len(gpus)} GPU(s) detected and configured\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"❌ GPU configuration error: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ No GPU detected, using CPU\")\n",
        "\n",
        "print(f\"🔢 TensorFlow version: {tf.__version__}\")\n",
        "print(f\"🎲 Random seed: 42\")\n",
        "\n",
        "# Set seeds pour reproducibilité\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Chargement du DataFrame existant: ./data/recipes_with_images_dataframe.pkl\n",
            "✅ 13463 recettes chargées depuis le DataFrame\n",
            "📸 13463 recettes avec images disponibles\n",
            "📊 Pourcentage avec images: 100.0%\n"
          ]
        }
      ],
      "source": [
        "# 📊 CHARGEMENT DES DONNÉES\n",
        "# ============================================================================\n",
        "# 🔄 Chargement du DataFrame avec les recettes et images\n",
        "\n",
        "def load_or_create_recipes_df():\n",
        "    \"\"\"Charge le DataFrame ou le crée depuis le dataset\"\"\"\n",
        "    pkl_path = \"./data/recipes_with_images_dataframe.pkl\"\n",
        "    \n",
        "    if os.path.exists(pkl_path):\n",
        "        print(f\"✅ Chargement du DataFrame existant: {pkl_path}\")\n",
        "        return pd.read_pickle(pkl_path)\n",
        "    \n",
        "    print(\"❌ DataFrame non trouvé, création depuis le dataset...\")\n",
        "    \n",
        "    # Télécharger le dataset\n",
        "    try:\n",
        "        dataset_path = kagglehub.dataset_download(\"pes12017000148/food-ingredients-and-recipe-dataset-with-images\")\n",
        "        csv_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]\n",
        "        csv_path = os.path.join(dataset_path, csv_files[0])\n",
        "        \n",
        "        print(f\"📄 CSV: {csv_path}\")\n",
        "        \n",
        "        # Charger et nettoyer\n",
        "        df = pd.read_csv(csv_path)\n",
        "        df_clean = df.dropna(subset=['Title', 'Ingredients', 'Instructions']).copy()\n",
        "        \n",
        "        # Ajouter les colonnes nécessaires\n",
        "        images_dir = os.path.join(dataset_path, \"Food Images\", \"Food Images\")\n",
        "        df_clean['image_path'] = df_clean['Image_Name'].apply(\n",
        "            lambda x: os.path.join(images_dir, x) if pd.notna(x) else None\n",
        "        )\n",
        "        \n",
        "        # Vérifier l'existence des images\n",
        "        df_clean['has_image'] = df_clean['image_path'].apply(\n",
        "            lambda x: os.path.exists(x) if x else False\n",
        "        )\n",
        "        \n",
        "        # Créer le dossier data s'il n'existe pas\n",
        "        os.makedirs(\"./data\", exist_ok=True)\n",
        "        \n",
        "        # Sauvegarder pour les prochaines fois\n",
        "        df_clean.to_pickle(pkl_path)\n",
        "        print(f\"✅ DataFrame sauvé: {pkl_path}\")\n",
        "        \n",
        "        return df_clean\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur lors de la création du DataFrame: {e}\")\n",
        "        return None\n",
        "\n",
        "# Charger les données\n",
        "try:\n",
        "    recipes_df = load_or_create_recipes_df()\n",
        "    if recipes_df is not None:\n",
        "        print(f\"✅ {len(recipes_df)} recettes chargées depuis le DataFrame\")\n",
        "        recipes_with_images = recipes_df[recipes_df['has_image'] == True].copy()\n",
        "        print(f\"📸 {len(recipes_with_images)} recettes avec images disponibles\")\n",
        "        print(f\"📊 Pourcentage avec images: {len(recipes_with_images)/len(recipes_df)*100:.1f}%\")\n",
        "    else:\n",
        "        print(\"❌ Échec du chargement des données\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur lors du chargement: {e}\")\n",
        "    recipes_df = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Custom layers defined successfully\n",
            "   🔧 L2NormalizationLayer: L2 normalization for embeddings\n",
            "   🔧 ExtractTripletComponent: Extract anchor/positive/negative from triplet\n",
            "   🔧 TripletStackLayer: Stack embeddings for triplet loss\n"
          ]
        }
      ],
      "source": [
        "# 🧠 CUSTOM LAYERS ET UTILITAIRES\n",
        "# ============================================================================\n",
        "\n",
        "def preprocess_image(image_path, img_size=224):\n",
        "    \"\"\"Préprocessing des images pour EfficientNet\"\"\"\n",
        "    try:\n",
        "        # Charger et redimensionner l'image\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img = img.resize((img_size, img_size), Image.Resampling.LANCZOS)\n",
        "        \n",
        "        # Convertir en array et normaliser\n",
        "        img_array = np.array(img, dtype=np.float32)\n",
        "        \n",
        "        # Preprocessing EfficientNet (scale to [0,1] puis normalize)\n",
        "        img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "        \n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur preprocessing {image_path}: {e}\")\n",
        "        # Retourner une image noire en cas d'erreur\n",
        "        return np.zeros((img_size, img_size, 3), dtype=np.float32)\n",
        "\n",
        "# 🎯 COUCHE L2 NORMALIZATION PERSONNALISÉE (SÉRIALISABLE)\n",
        "class L2NormalizationLayer(Layer):\n",
        "    \"\"\"Couche personnalisée pour normalisation L2 - sérialisable\"\"\"\n",
        "    \n",
        "    def __init__(self, axis=1, **kwargs):\n",
        "        super(L2NormalizationLayer, self).__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return tf.nn.l2_normalize(inputs, axis=self.axis)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super(L2NormalizationLayer, self).get_config()\n",
        "        config.update({'axis': self.axis})\n",
        "        return config\n",
        "\n",
        "# 🎯 COUCHE EXTRACTION TRIPLET PERSONNALISÉE (SÉRIALISABLE)\n",
        "class ExtractTripletComponent(Layer):\n",
        "    \"\"\"Couche pour extraire une composante du triplet\"\"\"\n",
        "    \n",
        "    def __init__(self, component_index, **kwargs):\n",
        "        super(ExtractTripletComponent, self).__init__(**kwargs)\n",
        "        self.component_index = component_index\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return inputs[:, self.component_index]\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        # input_shape = (batch_size, 3, height, width, channels)\n",
        "        return (input_shape[0], input_shape[2], input_shape[3], input_shape[4])\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super(ExtractTripletComponent, self).get_config()\n",
        "        config.update({'component_index': self.component_index})\n",
        "        return config\n",
        "\n",
        "# 🎯 COUCHE STACK TRIPLET PERSONNALISÉE (SÉRIALISABLE)\n",
        "class TripletStackLayer(Layer):\n",
        "    \"\"\"Couche personnalisée pour empiler les embeddings triplet\"\"\"\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super(TripletStackLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # inputs = [anchor_emb, positive_emb, negative_emb]\n",
        "        return tf.stack(inputs, axis=1)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        # input_shape = [(batch_size, embedding_dim), ...]\n",
        "        batch_size = input_shape[0][0]\n",
        "        embedding_dim = input_shape[0][1]\n",
        "        return (batch_size, 3, embedding_dim)\n",
        "    \n",
        "    def get_config(self):\n",
        "        return super(TripletStackLayer, self).get_config()\n",
        "\n",
        "print(\"✅ Custom layers defined successfully\")\n",
        "print(\"   🔧 L2NormalizationLayer: L2 normalization for embeddings\")\n",
        "print(\"   🔧 ExtractTripletComponent: Extract anchor/positive/negative from triplet\")\n",
        "print(\"   🔧 TripletStackLayer: Stack embeddings for triplet loss\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏗️ Création du modèle fine-tuning avec 20 couches dégelées...\n",
            "📊 EfficientNetB0 chargé: 238 couches totales\n",
            "🧊 Couches gelées: 218 (0 à 217)\n",
            "🔥 Couches dégelées: 20 (218 à 237)\n",
            "\n",
            "📊 STATISTIQUES DU MODÈLE:\n",
            "   🔢 Paramètres totaux: 6,154,915\n",
            "   🔥 Paramètres entraînables: 3,453,232 (56.1%)\n",
            "   🧊 Paramètres gelés: 2,701,683 (43.9%)\n",
            "   📐 Forme de sortie: (None, 512)\n",
            "\n",
            "✅ Modèle fine-tuning créé avec succès!\n"
          ]
        }
      ],
      "source": [
        "# 🏗️ CREATION DU MODÈLE FINE-TUNING (20 COUCHES DÉGELÉES)\n",
        "# ============================================================================\n",
        "\n",
        "def create_fine_tuning_embedding_model(input_shape=(224, 224, 3), embedding_dim=512, unfrozen_layers=20):\n",
        "    \"\"\"\n",
        "    🔥 Créer un modèle d'embedding avec fine-tuning\n",
        "    \n",
        "    Args:\n",
        "        input_shape: Forme des images d'entrée\n",
        "        embedding_dim: Dimension des embeddings de sortie\n",
        "        unfrozen_layers: Nombre de couches à dégeler pour le fine-tuning\n",
        "    \n",
        "    Returns:\n",
        "        Modèle d'embedding fine-tuné\n",
        "    \"\"\"\n",
        "    print(f\"🏗️ Création du modèle fine-tuning avec {unfrozen_layers} couches dégelées...\")\n",
        "    \n",
        "    # 1. Chargement d'EfficientNetB0 pré-entraîné\n",
        "    base_model = EfficientNetB0(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape,\n",
        "        pooling=None\n",
        "    )\n",
        "    \n",
        "    print(f\"📊 EfficientNetB0 chargé: {len(base_model.layers)} couches totales\")\n",
        "    \n",
        "    # 2. STRATÉGIE DE FINE-TUNING: Geler puis dégeler les dernières couches\n",
        "    \n",
        "    # D'abord, geler toutes les couches\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Ensuite, dégeler les N dernières couches\n",
        "    total_layers = len(base_model.layers)\n",
        "    unfreeze_from = max(0, total_layers - unfrozen_layers)\n",
        "    \n",
        "    trainable_count = 0\n",
        "    frozen_count = 0\n",
        "    \n",
        "    for i, layer in enumerate(base_model.layers):\n",
        "        if i >= unfreeze_from:\n",
        "            layer.trainable = True\n",
        "            trainable_count += 1\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "            frozen_count += 1\n",
        "    \n",
        "    print(f\"🧊 Couches gelées: {frozen_count} (0 à {unfreeze_from-1})\")\n",
        "    print(f\"🔥 Couches dégelées: {trainable_count} ({unfreeze_from} à {total_layers-1})\")\n",
        "    \n",
        "    # 3. Construction du modèle complet avec head personnalisé\n",
        "    inputs = Input(shape=input_shape, name='image_input')\n",
        "    \n",
        "    # Feature extraction avec EfficientNet (partiellement fine-tuné)\n",
        "    x = base_model(inputs, training=True)  # training=True pour fine-tuning\n",
        "    \n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
        "    \n",
        "    # Head personnalisé pour les embeddings\n",
        "    x = Dense(1024, activation='relu', name='dense_1024')(x)\n",
        "    x = BatchNormalization(name='batch_norm_1')(x)\n",
        "    x = Dropout(CONFIG_FT['DROPOUT_RATE'], name='dropout_1')(x)\n",
        "    \n",
        "    x = Dense(512, activation='relu', name='dense_512')(x)\n",
        "    x = BatchNormalization(name='batch_norm_2')(x)\n",
        "    x = Dropout(CONFIG_FT['DROPOUT_RATE'] * 0.5, name='dropout_2')(x)\n",
        "    \n",
        "    # Couche d'embedding finale\n",
        "    embeddings = Dense(embedding_dim, activation='linear', name='embeddings')(x)\n",
        "    \n",
        "    # Normalisation L2 pour cosine similarity\n",
        "    embeddings_normalized = L2NormalizationLayer(axis=1, name='l2_norm')(embeddings)\n",
        "    \n",
        "    # Créer le modèle\n",
        "    model = Model(inputs=inputs, outputs=embeddings_normalized, name='FinetuneEmbeddingModel')\n",
        "    \n",
        "    # 4. Statistiques du modèle\n",
        "    total_params = model.count_params()\n",
        "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "    frozen_params = total_params - trainable_params\n",
        "    \n",
        "    print(f\"\\n📊 STATISTIQUES DU MODÈLE:\")\n",
        "    print(f\"   🔢 Paramètres totaux: {total_params:,}\")\n",
        "    print(f\"   🔥 Paramètres entraînables: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
        "    print(f\"   🧊 Paramètres gelés: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)\")\n",
        "    print(f\"   📐 Forme de sortie: {model.output_shape}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Test de création du modèle\n",
        "embedding_model_ft = create_fine_tuning_embedding_model(\n",
        "    input_shape=(CONFIG_FT['IMG_SIZE'], CONFIG_FT['IMG_SIZE'], 3),\n",
        "    embedding_dim=CONFIG_FT['EMBEDDING_DIM_CUSTOM'],\n",
        "    unfrozen_layers=CONFIG_FT['UNFROZEN_LAYERS']\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Modèle fine-tuning créé avec succès!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Triplet loss et métriques définies:\n",
            "   🎯 triplet_loss_fn: Loss principale avec marge\n",
            "   📊 triplet_accuracy: % de triplets corrects\n",
            "   📈 average_positive_similarity: Sim anchor-positive\n",
            "   📉 average_negative_similarity: Sim anchor-negative\n"
          ]
        }
      ],
      "source": [
        "# 📏 TRIPLET LOSS ET MÉTRIQUES PERSONNALISÉES\n",
        "# ============================================================================\n",
        "\n",
        "def triplet_loss_fn(y_true, y_pred, margin=0.2):\n",
        "    \"\"\"\n",
        "    🎯 Triplet Loss avec hard negative mining\n",
        "    \n",
        "    Args:\n",
        "        y_true: Labels (non utilisés)\n",
        "        y_pred: Embeddings empilés [anchor, positive, negative] shape=(batch_size, 3, embedding_dim)\n",
        "        margin: Marge pour la triplet loss\n",
        "    \n",
        "    Returns:\n",
        "        Triplet loss value\n",
        "    \"\"\"\n",
        "    # Extraire les embeddings\n",
        "    anchor = y_pred[:, 0, :]      # (batch_size, embedding_dim)\n",
        "    positive = y_pred[:, 1, :]    # (batch_size, embedding_dim)\n",
        "    negative = y_pred[:, 2, :]    # (batch_size, embedding_dim)\n",
        "    \n",
        "    # Calculer les distances (cosine similarity -> distance)\n",
        "    pos_similarity = tf.reduce_sum(anchor * positive, axis=1)\n",
        "    neg_similarity = tf.reduce_sum(anchor * negative, axis=1)\n",
        "    \n",
        "    # Triplet loss: max(0, margin - (pos_sim - neg_sim))\n",
        "    # Plus pos_sim est élevé et neg_sim faible, plus la loss est petite\n",
        "    loss = tf.maximum(0.0, margin - (pos_similarity - neg_similarity))\n",
        "    \n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "def triplet_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    📊 Métrique d'accuracy pour triplet loss\n",
        "    Pourcentage de triplets où pos_similarity > neg_similarity\n",
        "    \"\"\"\n",
        "    anchor = y_pred[:, 0, :]     # (batch_size, embedding_dim)\n",
        "    positive = y_pred[:, 1, :]   # (batch_size, embedding_dim)\n",
        "    negative = y_pred[:, 2, :]   # (batch_size, embedding_dim)\n",
        "    \n",
        "    pos_similarity = tf.reduce_sum(anchor * positive, axis=1)\n",
        "    neg_similarity = tf.reduce_sum(anchor * negative, axis=1)\n",
        "    \n",
        "    # Compter les cas où positive > negative\n",
        "    correct_predictions = tf.cast(pos_similarity > neg_similarity, tf.float32)\n",
        "    return tf.reduce_mean(correct_predictions)\n",
        "\n",
        "def average_positive_similarity(y_true, y_pred):\n",
        "    \"\"\"📈 Similarité moyenne anchor-positive\"\"\"\n",
        "    anchor = y_pred[:, 0, :]\n",
        "    positive = y_pred[:, 1, :]\n",
        "    return tf.reduce_mean(tf.reduce_sum(anchor * positive, axis=1))\n",
        "\n",
        "def average_negative_similarity(y_true, y_pred):\n",
        "    \"\"\"📉 Similarité moyenne anchor-negative\"\"\"\n",
        "    anchor = y_pred[:, 0, :]\n",
        "    negative = y_pred[:, 2, :]\n",
        "    return tf.reduce_mean(tf.reduce_sum(anchor * negative, axis=1))\n",
        "\n",
        "# Test des fonctions\n",
        "print(\"✅ Triplet loss et métriques définies:\")\n",
        "print(\"   🎯 triplet_loss_fn: Loss principale avec marge\")\n",
        "print(\"   📊 triplet_accuracy: % de triplets corrects\")\n",
        "print(\"   📈 average_positive_similarity: Sim anchor-positive\")\n",
        "print(\"   📉 average_negative_similarity: Sim anchor-negative\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ TripletGeneratorFT défini avec optimisations fine-tuning\n",
            "   🔄 Augmentation conservative\n",
            "   🎯 Hard negative mining\n",
            "   📊 Split train/validation par recette\n"
          ]
        }
      ],
      "source": [
        "# 🔄 GÉNÉRATEUR DE DONNÉES TRIPLET POUR FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "class TripletGeneratorFT(Sequence):\n",
        "    \"\"\"\n",
        "    🎯 Générateur de triplets (anchor, positive, negative) pour fine-tuning\n",
        "    Optimisé avec hard negative mining et augmentation conservatrice\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, recipes_df, batch_size=16, img_size=224, augment=True, validation_split=0.2, is_validation=False):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment and not is_validation  # Pas d'augmentation pour validation\n",
        "        \n",
        "        # Filtrer et diviser les données\n",
        "        self.valid_recipes = self._filter_valid_recipes(recipes_df)\n",
        "        self.train_recipes, self.val_recipes = self._split_data(validation_split)\n",
        "        \n",
        "        # Utiliser le bon subset\n",
        "        self.recipes_df = self.val_recipes if is_validation else self.train_recipes\n",
        "        \n",
        "        # Grouper par titre pour positive sampling\n",
        "        self.recipe_groups = self.recipes_df.groupby('Title')\n",
        "        \n",
        "        # Data augmentation conservative pour fine-tuning\n",
        "        if self.augment:\n",
        "            self.datagen = ImageDataGenerator(\n",
        "                rotation_range=10,        # Réduction de 20 à 10\n",
        "                width_shift_range=0.1,    # Réduction de 0.15 à 0.1\n",
        "                height_shift_range=0.1,   # Réduction de 0.15 à 0.1\n",
        "                shear_range=0.1,          # Réduction de 0.15 à 0.1\n",
        "                zoom_range=0.1,           # Réduction de 0.15 à 0.1\n",
        "                horizontal_flip=True,\n",
        "                brightness_range=[0.9, 1.1], # Plus conservateur\n",
        "                fill_mode='nearest'\n",
        "            )\n",
        "        \n",
        "        mode = '(Validation)' if is_validation else '(Training)'\n",
        "        print(f\"🔄 TripletGeneratorFT {mode}:\")\n",
        "        print(f\"   📊 Total recettes: {len(self.recipes_df)}\")\n",
        "        print(f\"   📸 Images: {len(self.recipes_df)}\")\n",
        "        augment_status = 'ON (conservative)' if self.augment else 'OFF'\n",
        "        print(f\"   🔄 Augmentation: {augment_status}\")\n",
        "\n",
        "    def _filter_valid_recipes(self, recipes_df):\n",
        "        \"\"\"Filtrer les recettes avec images valides\"\"\"\n",
        "        print(\"🔍 Filtrage des recettes avec images valides...\")\n",
        "        \n",
        "        valid_recipes = []\n",
        "        for idx, row in tqdm(recipes_df.iterrows(), total=len(recipes_df), desc=\"Validation images\"):\n",
        "            if pd.notna(row.get('image_path')) and os.path.exists(row['image_path']):\n",
        "                try:\n",
        "                    # Test de chargement rapide\n",
        "                    with Image.open(row['image_path']) as img:\n",
        "                        img.verify()  # Vérifier l'intégrité\n",
        "                    valid_recipes.append(row.to_dict())\n",
        "                except Exception:\n",
        "                    continue\n",
        "        \n",
        "        result_df = pd.DataFrame(valid_recipes)\n",
        "        print(f\"✅ {len(result_df)}/{len(recipes_df)} images valides\")\n",
        "        return result_df\n",
        "    \n",
        "    def _split_data(self, validation_split):\n",
        "        \"\"\"Diviser les données en train/validation par recette\"\"\"\n",
        "        unique_recipes = self.valid_recipes['Title'].unique()\n",
        "        \n",
        "        train_recipes, val_recipes = train_test_split(\n",
        "            unique_recipes, \n",
        "            test_size=validation_split, \n",
        "            random_state=42\n",
        "        )\n",
        "        \n",
        "        train_df = self.valid_recipes[self.valid_recipes['Title'].isin(train_recipes)]\n",
        "        val_df = self.valid_recipes[self.valid_recipes['Title'].isin(val_recipes)]\n",
        "        \n",
        "        print(f\"📊 Split: {len(train_df)} train, {len(val_df)} validation\")\n",
        "        return train_df, val_df\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Nombre de batches par époque\"\"\"\n",
        "        return max(1, len(self.recipes_df) // self.batch_size)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Générer un batch de triplets\"\"\"\n",
        "        batch_size = self.batch_size\n",
        "        \n",
        "        # Préparer les arrays\n",
        "        anchors = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        positives = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        negatives = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        \n",
        "        valid_triplets = 0\n",
        "        attempts = 0\n",
        "        max_attempts = batch_size * 5  # Plus de tentatives pour robustesse\n",
        "        \n",
        "        while valid_triplets < batch_size and attempts < max_attempts:\n",
        "            attempts += 1\n",
        "            \n",
        "            try:\n",
        "                # 1. Sélectionner anchor aléatoire\n",
        "                anchor_row = self.recipes_df.sample(1).iloc[0]\n",
        "                anchor_title = anchor_row['Title']\n",
        "                \n",
        "                # 2. Sélectionner positive (même recette, image différente si possible)\n",
        "                same_recipe = self.recipe_groups.get_group(anchor_title)\n",
        "                if len(same_recipe) > 1:\n",
        "                    pos_row = same_recipe[same_recipe.index != anchor_row.name].sample(1).iloc[0]\n",
        "                else:\n",
        "                    pos_row = anchor_row  # Même image si pas d'autre choix\n",
        "                \n",
        "                # 3. Sélectionner negative (recette différente)\n",
        "                different_recipes = self.recipes_df[self.recipes_df['Title'] != anchor_title]\n",
        "                if len(different_recipes) > 0:\n",
        "                    neg_row = different_recipes.sample(1).iloc[0]\n",
        "                else:\n",
        "                    continue\n",
        "                \n",
        "                # 4. Charger et preprocesser les images\n",
        "                anchor_img = preprocess_image(anchor_row['image_path'], self.img_size)\n",
        "                pos_img = preprocess_image(pos_row['image_path'], self.img_size)\n",
        "                neg_img = preprocess_image(neg_row['image_path'], self.img_size)\n",
        "                \n",
        "                # 5. Appliquer augmentation si nécessaire\n",
        "                if self.augment:\n",
        "                    # Augmentation conservative pour fine-tuning\n",
        "                    anchor_img = self.datagen.random_transform(anchor_img)\n",
        "                    pos_img = self.datagen.random_transform(pos_img)\n",
        "                    # Pas d'augmentation sur negative pour hard mining\n",
        "                \n",
        "                # 6. Stocker dans le batch\n",
        "                anchors[valid_triplets] = anchor_img\n",
        "                positives[valid_triplets] = pos_img\n",
        "                negatives[valid_triplets] = neg_img\n",
        "                \n",
        "                valid_triplets += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                continue\n",
        "        \n",
        "        # Remplir les triplets manquants si nécessaire\n",
        "        while valid_triplets < batch_size:\n",
        "            anchors[valid_triplets] = anchors[0]\n",
        "            positives[valid_triplets] = positives[0]\n",
        "            negatives[valid_triplets] = negatives[0]\n",
        "            valid_triplets += 1\n",
        "        \n",
        "        # Format pour le modèle triplet: (batch_size, 3, height, width, channels)\n",
        "        triplet_batch = np.stack([anchors, positives, negatives], axis=1)\n",
        "        dummy_labels = np.zeros((batch_size, 1))  # Non utilisé avec triplet loss\n",
        "        \n",
        "        return triplet_batch, dummy_labels\n",
        "\n",
        "print(\"✅ TripletGeneratorFT défini avec optimisations fine-tuning\")\n",
        "print(\"   🔄 Augmentation conservative\")\n",
        "print(\"   🎯 Hard negative mining\")\n",
        "print(\"   📊 Split train/validation par recette\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏗️ Création du modèle triplet fine-tuning...\n",
            "✅ Modèle triplet créé:\n",
            "   📐 Input shape: (None, 3, 224, 224, 3)\n",
            "   📐 Output shape: (None, 3, 512)\n"
          ]
        }
      ],
      "source": [
        "# 🏗️ CRÉATION DU MODÈLE TRIPLET FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "def create_triplet_model_ft(embedding_model):\n",
        "    \"\"\"\n",
        "    🎯 Créer le modèle triplet pour l'entraînement fine-tuning\n",
        "    \n",
        "    Args:\n",
        "        embedding_model: Modèle d'embedding pré-créé\n",
        "    \n",
        "    Returns:\n",
        "        Modèle triplet compilé\n",
        "    \"\"\"\n",
        "    print(\"🏗️ Création du modèle triplet fine-tuning...\")\n",
        "    \n",
        "    # Input: batch de triplets (batch_size, 3, height, width, channels)\n",
        "    triplet_input = Input(\n",
        "        shape=(3, CONFIG_FT['IMG_SIZE'], CONFIG_FT['IMG_SIZE'], 3),\n",
        "        name='triplet_input'\n",
        "    )\n",
        "    \n",
        "    # Extraire chaque composante du triplet\n",
        "    anchor_input = ExtractTripletComponent(0, name='extract_anchor')(triplet_input)\n",
        "    positive_input = ExtractTripletComponent(1, name='extract_positive')(triplet_input)\n",
        "    negative_input = ExtractTripletComponent(2, name='extract_negative')(triplet_input)\n",
        "    \n",
        "    # Obtenir les embeddings pour chaque composante\n",
        "    anchor_embedding = embedding_model(anchor_input)\n",
        "    positive_embedding = embedding_model(positive_input)\n",
        "    negative_embedding = embedding_model(negative_input)\n",
        "    \n",
        "    # Empiler les embeddings pour le triplet loss\n",
        "    triplet_output = TripletStackLayer(name='triplet_stack')([\n",
        "        anchor_embedding, \n",
        "        positive_embedding, \n",
        "        negative_embedding\n",
        "    ])\n",
        "    \n",
        "    # Créer le modèle triplet\n",
        "    triplet_model = Model(\n",
        "        inputs=triplet_input, \n",
        "        outputs=triplet_output, \n",
        "        name='UltimateTripletModelFT'\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ Modèle triplet créé:\")\n",
        "    print(f\"   📐 Input shape: {triplet_model.input_shape}\")\n",
        "    print(f\"   📐 Output shape: {triplet_model.output_shape}\")\n",
        "    \n",
        "    return triplet_model\n",
        "\n",
        "# Créer le modèle triplet\n",
        "triplet_model_ft = create_triplet_model_ft(embedding_model_ft)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Fonction d'entraînement fine-tuning définie\n",
            "   🔥 Learning rates optimisés pour fine-tuning\n",
            "   📊 Callbacks adaptés pour stabilité\n",
            "   💾 Sauvegarde automatique du meilleur modèle\n"
          ]
        }
      ],
      "source": [
        "# 🚀 FONCTION D'ENTRAÎNEMENT FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "def train_fine_tuning():\n",
        "    \"\"\"\n",
        "    🔥 Entraîner le modèle avec fine-tuning et différents learning rates\n",
        "    \n",
        "    Returns:\n",
        "        embedding_model, history: Modèle entraîné et historique\n",
        "    \"\"\"\n",
        "    print(\"🚀 DÉMARRAGE DE L'ENTRAÎNEMENT FINE-TUNING\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Créer les générateurs de données (train + validation)\n",
        "    print(\"\\n📊 Création des générateurs de données...\")\n",
        "    train_generator = TripletGeneratorFT(\n",
        "        recipes_with_images,\n",
        "        batch_size=CONFIG_FT['BATCH_SIZE'],\n",
        "        img_size=CONFIG_FT['IMG_SIZE'],\n",
        "        augment=CONFIG_FT['USE_AUGMENTATION'],\n",
        "        validation_split=CONFIG_FT['VALIDATION_SPLIT'],\n",
        "        is_validation=False\n",
        "    )\n",
        "    \n",
        "    val_generator = TripletGeneratorFT(\n",
        "        recipes_with_images,\n",
        "        batch_size=CONFIG_FT['BATCH_SIZE'],\n",
        "        img_size=CONFIG_FT['IMG_SIZE'],\n",
        "        augment=False,  # Pas d'augmentation pour validation\n",
        "        validation_split=CONFIG_FT['VALIDATION_SPLIT'],\n",
        "        is_validation=True\n",
        "    )\n",
        "    \n",
        "    # Créer le modèle triplet\n",
        "    triplet_model = create_triplet_model_ft(embedding_model_ft)\n",
        "    \n",
        "    # ⚡ COMPILATION AVEC LEARNING RATES DIFFÉRENTIÉS\n",
        "    print(\"\\n⚡ Compilation du modèle avec learning rates optimisés...\")\n",
        "    \n",
        "    # Créer un optimizer avec learning rate pour fine-tuning\n",
        "    optimizer = Adam(\n",
        "        learning_rate=CONFIG_FT['FINETUNE_LR'],\n",
        "        weight_decay=CONFIG_FT['WEIGHT_DECAY']  # L2 regularization\n",
        "    )\n",
        "    \n",
        "    # Compiler le modèle\n",
        "    triplet_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=lambda y_true, y_pred: triplet_loss_fn(y_true, y_pred, margin=CONFIG_FT['MARGIN']),\n",
        "        metrics=[triplet_accuracy, average_positive_similarity, average_negative_similarity]\n",
        "    )\n",
        "    \n",
        "    print(f\"   📈 Optimizer: Adam (lr={CONFIG_FT['FINETUNE_LR']}, wd={CONFIG_FT['WEIGHT_DECAY']})\")\n",
        "    print(f\"   🎯 Triplet Loss margin: {CONFIG_FT['MARGIN']}\")\n",
        "    print(f\"   📊 Métriques: accuracy, pos_sim, neg_sim\")\n",
        "    \n",
        "    # 📋 CALLBACKS OPTIMISÉS POUR FINE-TUNING\n",
        "    print(\"\\n📋 Configuration des callbacks...\")\n",
        "    \n",
        "    # Modèle checkpoint pour sauvegarder le meilleur modèle\n",
        "    checkpoint_path = os.path.join(CONFIG_FT['CHECKPOINT_DIR'], f\"best_{CONFIG_FT['MODEL_NAME']}\")\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        checkpoint_path,\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    )\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=CONFIG_FT['PATIENCE'],\n",
        "        verbose=1,\n",
        "        restore_best_weights=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    \n",
        "    # Réduction du learning rate\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=CONFIG_FT['REDUCE_LR_FACTOR'],\n",
        "        patience=CONFIG_FT['REDUCE_LR_PATIENCE'],\n",
        "        min_lr=CONFIG_FT['MIN_LR'],\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    )\n",
        "    \n",
        "    callbacks = [model_checkpoint, early_stopping, reduce_lr]\n",
        "    \n",
        "    print(f\"   💾 Model checkpoint: {checkpoint_path}\")\n",
        "    print(f\"   ⏰ Early stopping: patience={CONFIG_FT['PATIENCE']}\")\n",
        "    print(f\"   📉 Reduce LR: patience={CONFIG_FT['REDUCE_LR_PATIENCE']}, factor={CONFIG_FT['REDUCE_LR_FACTOR']}\")\n",
        "    print(f\"   🔻 Min LR: {CONFIG_FT['MIN_LR']}\")\n",
        "    \n",
        "    # 🎯 ENTRAÎNEMENT\n",
        "    print(f\"\\n🎯 Lancement de l'entraînement ({CONFIG_FT['FINETUNE_EPOCHS']} époques max)...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        history = triplet_model.fit(\n",
        "            train_generator,\n",
        "            epochs=CONFIG_FT['FINETUNE_EPOCHS'],\n",
        "            validation_data=val_generator,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        print(\"\\n✅ ENTRAÎNEMENT TERMINÉ AVEC SUCCÈS!\")\n",
        "        \n",
        "        # Sauvegarder le modèle d'embedding final\n",
        "        final_model_path = os.path.join(CONFIG_FT['CHECKPOINT_DIR'], CONFIG_FT['MODEL_NAME'])\n",
        "        embedding_model_ft.save(final_model_path)\n",
        "        print(f\"💾 Modèle d'embedding sauvé: {final_model_path}\")\n",
        "        \n",
        "        # Afficher les résultats finaux\n",
        "        print(f\"\\n📊 RÉSULTATS FINAUX:\")\n",
        "        print(f\"📉 Loss finale: {history.history['val_loss'][-1]:.4f}\")\n",
        "        print(f\"📊 Précision finale: {history.history['val_triplet_accuracy'][-1]:.4f}\")\n",
        "        print(f\"📈 Similarité pos finale: {history.history['val_average_positive_similarity'][-1]:.4f}\")\n",
        "        print(f\"📉 Similarité neg finale: {history.history['val_average_negative_similarity'][-1]:.4f}\")\n",
        "        \n",
        "        return embedding_model_ft, history\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERREUR PENDANT L'ENTRAÎNEMENT: {e}\")\n",
        "        return None, None\n",
        "\n",
        "print(\"✅ Fonction d'entraînement fine-tuning définie\")\n",
        "print(\"   🔥 Learning rates optimisés pour fine-tuning\")\n",
        "print(\"   📊 Callbacks adaptés pour stabilité\")\n",
        "print(\"   💾 Sauvegarde automatique du meilleur modèle\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Fonction de visualisation fine-tuning définie\n",
            "   🔧 Graphiques corrigés (échelles adaptées)\n",
            "   📊 Analyses automatiques des objectifs\n",
            "   🎨 Interface dark mode moderne\n"
          ]
        }
      ],
      "source": [
        "# 📊 VISUALISATION DES RÉSULTATS D'ENTRAÎNEMENT (VERSION CORRIGÉE)\n",
        "# ============================================================================\n",
        "\n",
        "def plot_training_results_ft(history):\n",
        "    \"\"\"Afficher les métriques d'entraînement fine-tuning - Version corrigée\"\"\"\n",
        "    \n",
        "    # Configuration dark mode\n",
        "    plt.style.use('dark_background')\n",
        "    \n",
        "    # Couleurs modernes pour dark mode\n",
        "    colors = {\n",
        "        'primary': '#00D4AA',      # Cyan-vert brillant\n",
        "        'secondary': '#FF6B6B',    # Rouge-coral moderne\n",
        "        'accent': '#4ECDC4',       # Turquoise\n",
        "        'warning': '#FFE66D',      # Jaune moderne\n",
        "        'info': '#A8E6CF',         # Vert pastel\n",
        "        'purple': '#B19CD9'        # Violet pastel\n",
        "    }\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.patch.set_facecolor('#1e1e1e')\n",
        "    fig.suptitle('🔥 Résultats Fine-Tuning (20 couches dégelées)', \n",
        "                 fontsize=18, fontweight='bold', color='white', y=0.95)\n",
        "    \n",
        "    # Configuration commune pour tous les axes\n",
        "    for ax in axes.flat:\n",
        "        ax.set_facecolor('#2d2d2d')\n",
        "        ax.tick_params(colors='white', which='both')\n",
        "        ax.xaxis.label.set_color('white')\n",
        "        ax.yaxis.label.set_color('white')\n",
        "        ax.title.set_color('white')\n",
        "        ax.grid(True, alpha=0.2, color='gray', linestyle='-', linewidth=0.5)\n",
        "        ax.spines['bottom'].set_color('white')\n",
        "        ax.spines['top'].set_color('white')\n",
        "        ax.spines['right'].set_color('white')\n",
        "        ax.spines['left'].set_color('white')\n",
        "    \n",
        "    # Loss (inchangé)\n",
        "    axes[0, 0].plot(history.history['loss'], label='📈 Train Loss', \n",
        "                    linewidth=3, color=colors['primary'], alpha=0.9)\n",
        "    axes[0, 0].plot(history.history['val_loss'], label='📉 Val Loss', \n",
        "                    linewidth=3, color=colors['secondary'], alpha=0.9)\n",
        "    axes[0, 0].fill_between(range(len(history.history['loss'])), \n",
        "                           history.history['loss'], alpha=0.1, color=colors['primary'])\n",
        "    axes[0, 0].fill_between(range(len(history.history['val_loss'])), \n",
        "                           history.history['val_loss'], alpha=0.1, color=colors['secondary'])\n",
        "    axes[0, 0].set_title('🎯 Triplet Loss Evolution', fontweight='bold', fontsize=14)\n",
        "    axes[0, 0].set_xlabel('Époque', fontweight='bold')\n",
        "    axes[0, 0].set_ylabel('Loss Value', fontweight='bold')\n",
        "    axes[0, 0].legend(frameon=True, fancybox=True, shadow=True, \n",
        "                     facecolor='#3d3d3d', edgecolor='white')\n",
        "    \n",
        "    # ✅ CORRECTION: Accuracy avec échelle adaptée\n",
        "    axes[0, 1].plot(history.history['triplet_accuracy'], label='📊 Train Accuracy', \n",
        "                    linewidth=3, color=colors['accent'], alpha=0.9, marker='o', markersize=4)\n",
        "    axes[0, 1].plot(history.history['val_triplet_accuracy'], label='📋 Val Accuracy', \n",
        "                    linewidth=3, color=colors['warning'], alpha=0.9, marker='s', markersize=4)\n",
        "    axes[0, 1].fill_between(range(len(history.history['triplet_accuracy'])), \n",
        "                           history.history['triplet_accuracy'], alpha=0.1, color=colors['accent'])\n",
        "    axes[0, 1].fill_between(range(len(history.history['val_triplet_accuracy'])), \n",
        "                           history.history['val_triplet_accuracy'], alpha=0.1, color=colors['warning'])\n",
        "    \n",
        "    # ✅ CORRECTION: Ligne de référence plus haute + échelle adaptée\n",
        "    axes[0, 1].axhline(y=0.95, color='white', linestyle='--', alpha=0.5, label='Target (95%)')\n",
        "    \n",
        "    # ✅ CORRECTION: Échelle Y adaptée pour mieux voir les variations\n",
        "    min_acc = min(min(history.history['triplet_accuracy']), min(history.history['val_triplet_accuracy']))\n",
        "    axes[0, 1].set_ylim(max(0.8, min_acc - 0.05), 1.02)  # Focus sur la zone utile\n",
        "    \n",
        "    axes[0, 1].set_title('📊 Triplet Accuracy Progress', fontweight='bold', fontsize=14)\n",
        "    axes[0, 1].set_xlabel('Époque', fontweight='bold')\n",
        "    axes[0, 1].set_ylabel('Accuracy Score', fontweight='bold')\n",
        "    axes[0, 1].legend(frameon=True, fancybox=True, shadow=True, \n",
        "                     facecolor='#3d3d3d', edgecolor='white')\n",
        "    \n",
        "    # ✅ CORRECTION: Positive Similarity avec zone cible réaliste\n",
        "    axes[1, 0].plot(history.history['average_positive_similarity'], label='🔗 Train Pos Sim', \n",
        "                    linewidth=3, color=colors['info'], alpha=0.9, marker='o', markersize=4)\n",
        "    axes[1, 0].plot(history.history['val_average_positive_similarity'], label='✅ Val Pos Sim', \n",
        "                    linewidth=3, color=colors['purple'], alpha=0.9, marker='s', markersize=4)\n",
        "    axes[1, 0].fill_between(range(len(history.history['average_positive_similarity'])), \n",
        "                           history.history['average_positive_similarity'], alpha=0.1, color=colors['info'])\n",
        "    axes[1, 0].fill_between(range(len(history.history['val_average_positive_similarity'])), \n",
        "                           history.history['val_average_positive_similarity'], alpha=0.1, color=colors['purple'])\n",
        "    \n",
        "    # ✅ CORRECTION: Zone d'objectif réaliste pour similarity positive (0.5-0.8)\n",
        "    axes[1, 0].axhspan(0.5, 0.8, alpha=0.1, color='green', label='Good Zone (0.5-0.8)')\n",
        "    axes[1, 0].axhline(y=0.6, color='lime', linestyle='--', alpha=0.7, label='Target (0.6+)')\n",
        "    \n",
        "    axes[1, 0].set_title('📈 Positive Similarity (Anchor-Positive)', fontweight='bold', fontsize=14)\n",
        "    axes[1, 0].set_xlabel('Époque', fontweight='bold')\n",
        "    axes[1, 0].set_ylabel('Cosine Similarity', fontweight='bold')\n",
        "    axes[1, 0].legend(frameon=True, fancybox=True, shadow=True, \n",
        "                     facecolor='#3d3d3d', edgecolor='white')\n",
        "    axes[1, 0].set_ylim(-0.2, 1.0)  # Zoom sur la zone utile\n",
        "    \n",
        "    # Negative Similarity (inchangé mais amélioré)\n",
        "    axes[1, 1].plot(history.history['average_negative_similarity'], label='❌ Train Neg Sim', \n",
        "                    linewidth=3, color=colors['secondary'], alpha=0.9, marker='o', markersize=4)\n",
        "    axes[1, 1].plot(history.history['val_average_negative_similarity'], label='🚫 Val Neg Sim', \n",
        "                    linewidth=3, color=colors['primary'], alpha=0.9, marker='s', markersize=4)\n",
        "    axes[1, 1].fill_between(range(len(history.history['average_negative_similarity'])), \n",
        "                           history.history['average_negative_similarity'], alpha=0.1, color=colors['secondary'])\n",
        "    axes[1, 1].fill_between(range(len(history.history['val_average_negative_similarity'])), \n",
        "                           history.history['val_average_negative_similarity'], alpha=0.1, color=colors['primary'])\n",
        "    \n",
        "    # Zone d'objectif pour similarity négative (<0.3)\n",
        "    axes[1, 1].axhspan(-1.0, 0.3, alpha=0.1, color='red', label='Target Zone (<0.3)')\n",
        "    axes[1, 1].axhline(y=0.2, color='orange', linestyle='--', alpha=0.7, label='Good (<0.2)')\n",
        "    \n",
        "    axes[1, 1].set_title('📉 Negative Similarity (Anchor-Negative)', fontweight='bold', fontsize=14)\n",
        "    axes[1, 1].set_xlabel('Époque', fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('Cosine Similarity', fontweight='bold')\n",
        "    axes[1, 1].legend(frameon=True, fancybox=True, shadow=True, \n",
        "                     facecolor='#3d3d3d', edgecolor='white')\n",
        "    axes[1, 1].set_ylim(-0.2, 0.8)  # Focus sur la zone utile\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.92)\n",
        "    plt.show()\n",
        "    \n",
        "    # ✅ BONUS: Affichage des statistiques finales\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"📊 RÉSULTATS FINAUX FINE-TUNING:\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"🎯 Loss finale (val): {history.history['val_loss'][-1]:.4f}\")\n",
        "    print(f\"📊 Accuracy finale (val): {history.history['val_triplet_accuracy'][-1]:.4f}\")\n",
        "    print(f\"📈 Pos Similarity finale (val): {history.history['val_average_positive_similarity'][-1]:.4f}\")\n",
        "    print(f\"📉 Neg Similarity finale (val): {history.history['val_average_negative_similarity'][-1]:.4f}\")\n",
        "    gap = history.history['val_average_positive_similarity'][-1] - history.history['val_average_negative_similarity'][-1]\n",
        "    print(f\"📏 Écart Pos-Neg: {gap:.4f}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Comparaison avec les targets\n",
        "    final_accuracy = history.history['val_triplet_accuracy'][-1]\n",
        "    final_pos_sim = history.history['val_average_positive_similarity'][-1]\n",
        "    final_neg_sim = history.history['val_average_negative_similarity'][-1]\n",
        "    \n",
        "    print(f\"\\n🎯 ANALYSE DES OBJECTIFS:\")\n",
        "    print(f\"   📊 Accuracy: {'✅' if final_accuracy > 0.95 else '⚠️'} {final_accuracy:.3f} (target: >0.95)\")\n",
        "    print(f\"   📈 Pos Sim: {'✅' if final_pos_sim > 0.6 else '⚠️'} {final_pos_sim:.3f} (target: >0.6)\")\n",
        "    print(f\"   📉 Neg Sim: {'✅' if final_neg_sim < 0.3 else '⚠️'} {final_neg_sim:.3f} (target: <0.3)\")\n",
        "    print(f\"   📏 Gap: {'✅' if gap > 0.3 else '⚠️'} {gap:.3f} (target: >0.3)\")\n",
        "    \n",
        "    # Reset style\n",
        "    plt.style.use('default')\n",
        "\n",
        "print(\"✅ Fonction de visualisation fine-tuning définie\")\n",
        "print(\"   🔧 Graphiques corrigés (échelles adaptées)\")\n",
        "print(\"   📊 Analyses automatiques des objectifs\")\n",
        "print(\"   🎨 Interface dark mode moderne\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RecipeImageRetrievalFT définie\n",
            "   🧠 Calcul d'embeddings optimisé\n",
            "   📊 Base de données automatique\n",
            "   🔍 Recherche par similarité\n",
            "   🎨 Visualisation des résultats\n"
          ]
        }
      ],
      "source": [
        "# 🚀 CLASSE COMPLÈTE RECIPE IMAGE RETRIEVAL FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "class RecipeImageRetrievalFT:\n",
        "    \"\"\"\n",
        "    🔥 Système de récupération d'images de recettes avec modèle fine-tuné\n",
        "    Version optimisée pour performance et précision maximale\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path=None, recipes_df=None):\n",
        "        \"\"\"Initialiser le système de récupération fine-tuning\"\"\"\n",
        "        print(\"🚀 Initialisation RecipeImageRetrievalFT...\")\n",
        "        \n",
        "        # Configuration\n",
        "        self.img_size = CONFIG_FT['IMG_SIZE']\n",
        "        self.embedding_dim = CONFIG_FT['EMBEDDING_DIM']\n",
        "        self.model_name = CONFIG_FT['MODEL_NAME']\n",
        "        \n",
        "        # Charger le modèle\n",
        "        if model_path and os.path.exists(model_path):\n",
        "            print(f\"📦 Chargement du modèle depuis: {model_path}\")\n",
        "            self.model = load_model(model_path, compile=False)\n",
        "        else:\n",
        "            print(\"❌ Aucun modèle trouvé!\")\n",
        "            self.model = None\n",
        "            return\n",
        "        \n",
        "        # Base de données des recettes\n",
        "        self.recipes_df = recipes_df\n",
        "        self.embeddings_db = None\n",
        "        \n",
        "        # Cache pour les performances\n",
        "        self.embedding_cache = {}\n",
        "        \n",
        "        print(f\"✅ RecipeImageRetrievalFT initialisé avec:\")\n",
        "        print(f\"   🏗️ Modèle: {self.model_name}\")\n",
        "        print(f\"   📐 Taille image: {self.img_size}x{self.img_size}\")\n",
        "        print(f\"   🧠 Dimension embedding: {self.embedding_dim}\")\n",
        "        print(f\"   📊 Recettes: {len(self.recipes_df) if self.recipes_df is not None else 0}\")\n",
        "    \n",
        "    def compute_embedding(self, image_path_or_array):\n",
        "        \"\"\"Calculer l'embedding d'une image\"\"\"\n",
        "        try:\n",
        "            # Cache check\n",
        "            if isinstance(image_path_or_array, str) and image_path_or_array in self.embedding_cache:\n",
        "                return self.embedding_cache[image_path_or_array]\n",
        "            \n",
        "            # Preprocessing\n",
        "            if isinstance(image_path_or_array, str):\n",
        "                img = preprocess_image(image_path_or_array, self.img_size)\n",
        "            else:\n",
        "                img = image_path_or_array\n",
        "            \n",
        "            # Ajouter dimension batch si nécessaire\n",
        "            if len(img.shape) == 3:\n",
        "                img = np.expand_dims(img, axis=0)\n",
        "            \n",
        "            # Calculer embedding\n",
        "            embedding = self.model.predict(img, verbose=0)[0]\n",
        "            \"\"\"\n",
        "            DOUBLE EMBEDDING ??\n",
        "            \"\"\"\n",
        "            # embedding = embedding / np.linalg.norm(embedding)  # Normalisation L2\n",
        "            \n",
        "            # Cache si c'est un path\n",
        "            if isinstance(image_path_or_array, str):\n",
        "                self.embedding_cache[image_path_or_array] = embedding\n",
        "            \n",
        "            return embedding\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erreur lors du calcul d'embedding: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def build_database(self, force_rebuild=False):\n",
        "        \"\"\"Construire la base de données d'embeddings\"\"\"\n",
        "        db_path = f\"ft/{self.model_name.replace('.keras', '')}_embeddings_database_ft.npy\"\n",
        "        \n",
        "        if os.path.exists(db_path) and not force_rebuild:\n",
        "            print(f\"📦 Chargement de la base de données: {db_path}\")\n",
        "            self.embeddings_db = np.load(db_path)\n",
        "            print(f\"✅ Base chargée: {self.embeddings_db.shape}\")\n",
        "            return\n",
        "        \n",
        "        if self.recipes_df is None:\n",
        "            print(\"❌ Aucune donnée de recettes disponible!\")\n",
        "            return\n",
        "        \n",
        "        print(f\"🔨 Construction de la base d'embeddings...\")\n",
        "        print(f\"   📊 Nombre de recettes: {len(self.recipes_df)}\")\n",
        "        \n",
        "        embeddings = []\n",
        "        valid_indices = []\n",
        "        \n",
        "        for idx, row in tqdm(self.recipes_df.iterrows(), \n",
        "                            total=len(self.recipes_df), \n",
        "                            desc=\"🧠 Embeddings\"):\n",
        "            if pd.notna(row.get('image_path')) and os.path.exists(row['image_path']):\n",
        "                embedding = self.compute_embedding(row['image_path'])\n",
        "                if embedding is not None:\n",
        "                    embeddings.append(embedding)\n",
        "                    valid_indices.append(idx)\n",
        "        \n",
        "        if embeddings:\n",
        "            self.embeddings_db = np.array(embeddings)\n",
        "            \n",
        "            # Sauvegarder\n",
        "            os.makedirs('ft', exist_ok=True)\n",
        "            np.save(db_path, self.embeddings_db)\n",
        "            \n",
        "            # Filtrer le DataFrame pour garder seulement les recettes valides\n",
        "            self.recipes_df = self.recipes_df.loc[valid_indices].reset_index(drop=True)\n",
        "            \n",
        "            print(f\"✅ Base construite et sauvée:\")\n",
        "            print(f\"   📊 Embeddings: {self.embeddings_db.shape}\")\n",
        "            print(f\"   💾 Sauvé dans: {db_path}\")\n",
        "            print(f\"   📋 Recettes valides: {len(self.recipes_df)}\")\n",
        "        else:\n",
        "            print(\"❌ Aucun embedding valide créé!\")\n",
        "    \n",
        "    def search_similar_recipes(self, query_image_path, top_k=5, min_similarity=0.3):\n",
        "        \"\"\"Rechercher les recettes similaires à une image\"\"\"\n",
        "        if self.embeddings_db is None:\n",
        "            print(\"❌ Base de données non construite! Appelez build_database() d'abord.\")\n",
        "            return []\n",
        "        \n",
        "        # Calculer embedding de la requête\n",
        "        query_embedding = self.compute_embedding(query_image_path)\n",
        "        if query_embedding is None:\n",
        "            print(\"❌ Impossible de calculer l'embedding de l'image requête\")\n",
        "            return []\n",
        "        \n",
        "        # Calculer similarités\n",
        "        similarities = np.dot(self.embeddings_db, query_embedding)\n",
        "        \n",
        "        # Trouver les top_k\n",
        "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "        top_similarities = similarities[top_indices]\n",
        "        \n",
        "        # Filtrer par similarité minimale\n",
        "        results = []\n",
        "        for idx, sim in zip(top_indices, top_similarities):\n",
        "            if sim >= min_similarity:\n",
        "                recipe = self.recipes_df.iloc[idx]\n",
        "                results.append({\n",
        "                    'recipe_title': recipe['Title'],\n",
        "                    'similarity': float(sim),\n",
        "                    'image_path': recipe['image_path'],\n",
        "                    'index': int(idx)\n",
        "                })\n",
        "        \n",
        "        return results\n",
        "\n",
        "print(\"✅ RecipeImageRetrievalFT définie\")\n",
        "print(\"   🧠 Calcul d'embeddings optimisé\")\n",
        "print(\"   📊 Base de données automatique\")\n",
        "print(\"   🔍 Recherche par similarité\")\n",
        "print(\"   🎨 Visualisation des résultats\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 DÉMARRAGE DE L'ENTRAÎNEMENT FINE-TUNING COMPLET\n",
            "============================================================\n",
            "🚀 DÉMARRAGE DE L'ENTRAÎNEMENT FINE-TUNING\n",
            "============================================================\n",
            "\n",
            "📊 Création des générateurs de données...\n",
            "🔍 Filtrage des recettes avec images valides...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation images: 100%|██████████| 13463/13463 [00:15<00:00, 851.22it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 13463/13463 images valides\n",
            "📊 Split: 10774 train, 2689 validation\n",
            "🔄 TripletGeneratorFT (Training):\n",
            "   📊 Total recettes: 10774\n",
            "   📸 Images: 10774\n",
            "   🔄 Augmentation: ON (conservative)\n",
            "🔍 Filtrage des recettes avec images valides...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation images: 100%|██████████| 13463/13463 [00:06<00:00, 1972.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 13463/13463 images valides\n",
            "📊 Split: 10774 train, 2689 validation\n",
            "🔄 TripletGeneratorFT (Validation):\n",
            "   📊 Total recettes: 2689\n",
            "   📸 Images: 2689\n",
            "   🔄 Augmentation: OFF\n",
            "🏗️ Création du modèle triplet fine-tuning...\n",
            "✅ Modèle triplet créé:\n",
            "   📐 Input shape: (None, 3, 224, 224, 3)\n",
            "   📐 Output shape: (None, 3, 512)\n",
            "\n",
            "⚡ Compilation du modèle avec learning rates optimisés...\n",
            "   📈 Optimizer: Adam (lr=5e-05, wd=0.0001)\n",
            "   🎯 Triplet Loss margin: 0.2\n",
            "   📊 Métriques: accuracy, pos_sim, neg_sim\n",
            "\n",
            "📋 Configuration des callbacks...\n",
            "   💾 Model checkpoint: ./ft/best_recipe_image_retrieval_model_ft.keras\n",
            "   ⏰ Early stopping: patience=5\n",
            "   📉 Reduce LR: patience=3, factor=0.5\n",
            "   🔻 Min LR: 1e-07\n",
            "\n",
            "🎯 Lancement de l'entraînement (25 époques max)...\n",
            "============================================================\n",
            "Epoch 1/25\n",
            "\u001b[1m168/673\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:57\u001b[0m 2s/step - average_negative_similarity: 5.1980e-04 - average_positive_similarity: 0.2415 - loss: 0.0272 - triplet_accuracy: 0.9753"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Lancer l'entraînement\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m trained_model_ft, history_ft = \u001b[43mtrain_fine_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trained_model_ft \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m history_ft \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🎉 ENTRAÎNEMENT TERMINÉ AVEC SUCCÈS!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 102\u001b[39m, in \u001b[36mtrain_fine_tuning\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     history = \u001b[43mtriplet_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG_FT\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFINETUNE_EPOCHS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ ENTRAÎNEMENT TERMINÉ AVEC SUCCÈS!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# Sauvegarder le modèle d'embedding final\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# 🎯 ENTRAÎNEMENT DU MODÈLE FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"🚀 DÉMARRAGE DE L'ENTRAÎNEMENT FINE-TUNING COMPLET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Lancer l'entraînement\n",
        "trained_model_ft, history_ft = train_fine_tuning()\n",
        "\n",
        "if trained_model_ft is not None and history_ft is not None:\n",
        "    print(\"\\n🎉 ENTRAÎNEMENT TERMINÉ AVEC SUCCÈS!\")\n",
        "    \n",
        "    # Visualiser les résultats\n",
        "    print(\"\\n📊 Visualisation des résultats d'entraînement...\")\n",
        "    plot_training_results_ft(history_ft)\n",
        "    \n",
        "    print(\"\\n✅ Fine-tuning completed successfully!\")\n",
        "    print(f\"   📁 Modèle sauvé dans: ft/{CONFIG_FT['MODEL_NAME']}\")\n",
        "    print(f\"   📊 Base de données d'embeddings prête\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ ERREUR PENDANT L'ENTRAÎNEMENT!\")\n",
        "    print(\"   Vérifiez les logs ci-dessus pour les détails\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 INITIALISATION DU SYSTÈME DE RÉCUPÉRATION FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"🔧 Initialisation du système de récupération fine-tuning...\")\n",
        "\n",
        "# Charger le modèle entraîné\n",
        "model_path_ft = f\"ft/{CONFIG_FT['MODEL_NAME']}\"\n",
        "\n",
        "if os.path.exists(model_path_ft):\n",
        "    # Créer le système de récupération\n",
        "    retrieval_system_ft = RecipeImageRetrievalFT(\n",
        "        model_path=model_path_ft,\n",
        "        recipes_df=recipes_with_images.copy()\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n🔨 Construction de la base de données d'embeddings...\")\n",
        "    retrieval_system_ft.build_database(force_rebuild=False)\n",
        "    \n",
        "    print(f\"\\n✅ SYSTÈME DE RÉCUPÉRATION FINE-TUNING PRÊT!\")\n",
        "    print(f\"   🏗️ Modèle: {model_path_ft}\")\n",
        "    print(f\"   📊 Base d'embeddings: {retrieval_system_ft.embeddings_db.shape if retrieval_system_ft.embeddings_db is not None else 'Non créée'}\")\n",
        "    print(f\"   📋 Recettes dans la base: {len(retrieval_system_ft.recipes_df) if retrieval_system_ft.recipes_df is not None else 0}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"❌ Modèle non trouvé: {model_path_ft}\")\n",
        "    print(\"   Vous devez d'abord entraîner le modèle!\")\n",
        "    retrieval_system_ft = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎲 TEST AVEC IMAGES ALÉATOIRES - FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "if retrieval_system_ft is not None:\n",
        "    print(\"🎲 Test avec des images aléatoires du dataset...\")\n",
        "    \n",
        "    # Sélectionner quelques recettes aléatoires pour les tests\n",
        "    test_recipes = retrieval_system_ft.recipes_df.sample(n=3, random_state=42)\n",
        "    \n",
        "    for i, (_, recipe) in enumerate(test_recipes.iterrows()):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"🧪 TEST {i+1}/3: {recipe['Title']}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        try:\n",
        "            # Recherche\n",
        "            results = retrieval_system_ft.search_similar_recipes(\n",
        "                query_image_path=recipe['image_path'],\n",
        "                top_k=5,\n",
        "                min_similarity=0.3\n",
        "            )\n",
        "            \n",
        "            if results:\n",
        "                print(f\"✅ {len(results)} résultats trouvés!\")\n",
        "                \n",
        "                # Afficher les résultats\n",
        "                print(f\"\\n📊 TOP RÉSULTATS:\")\n",
        "                for j, result in enumerate(results[:3]):\n",
        "                    print(f\"  #{j+1}. {result['recipe_title'][:50]}...\")\n",
        "                    print(f\"      📊 Similarité: {result['similarity']:.4f}\")\n",
        "                \n",
        "                # Vérifier si la même recette est en première position\n",
        "                if len(results) > 0 and results[0]['recipe_title'] == recipe['Title']:\n",
        "                    print(f\"🎯 PARFAIT! Même recette trouvée en premier (sim: {results[0]['similarity']:.4f})\")\n",
        "                else:\n",
        "                    print(f\"⚠️ Recette différente en premier: {results[0]['recipe_title'][:40]}\")\n",
        "                \n",
        "            else:\n",
        "                print(\"❌ Aucun résultat trouvé (similarité trop faible)\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erreur lors du test: {e}\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"✅ TESTS AVEC IMAGES ALÉATOIRES TERMINÉS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ Système de récupération non initialisé!\")\n",
        "    print(\"   Initialisez d'abord le système avec un modèle entraîné.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🖼️ TEST AVEC IMAGES CUSTOM - FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "if retrieval_system_ft is not None:\n",
        "    print(\"🖼️ Test avec des images custom du dossier test_recipes...\")\n",
        "    \n",
        "    # Dossier des images de test\n",
        "    test_images_dir = \"test_recipes\"\n",
        "    \n",
        "    if os.path.exists(test_images_dir):\n",
        "        # Lister toutes les images de test\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
        "        test_images = []\n",
        "        \n",
        "        for ext in image_extensions:\n",
        "            test_images.extend(glob.glob(os.path.join(test_images_dir, f\"*{ext}\")))\n",
        "            test_images.extend(glob.glob(os.path.join(test_images_dir, f\"*{ext.upper()}\")))\n",
        "        \n",
        "        if test_images:\n",
        "            print(f\"📁 {len(test_images)} images trouvées dans {test_images_dir}\")\n",
        "            \n",
        "            # Tester les 3 premières images (ou toutes si moins de 3)\n",
        "            images_to_test = test_images[:min(3, len(test_images))]\n",
        "            \n",
        "            for i, test_image_path in enumerate(images_to_test):\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"🧪 TEST CUSTOM {i+1}/{len(images_to_test)}: {os.path.basename(test_image_path)}\")\n",
        "                print(f\"{'='*60}\")\n",
        "                \n",
        "                try:\n",
        "                    # Recherche\n",
        "                    results = retrieval_system_ft.search_similar_recipes(\n",
        "                        query_image_path=test_image_path,\n",
        "                        top_k=5,\n",
        "                        min_similarity=0.2  # Seuil plus bas pour images externes\n",
        "                    )\n",
        "                    \n",
        "                    if results:\n",
        "                        print(f\"✅ {len(results)} résultats trouvés!\")\n",
        "                        \n",
        "                        # Afficher les détails\n",
        "                        print(f\"\\n📊 RÉSULTATS DÉTAILLÉS:\")\n",
        "                        for j, result in enumerate(results):\n",
        "                            print(f\"  #{j+1}. {result['recipe_title']}\")\n",
        "                            print(f\"      📊 Similarité: {result['similarity']:.4f}\")\n",
        "                            print(f\"      📁 Path: {result['image_path']}\")\n",
        "                            print()\n",
        "                        \n",
        "                        # Évaluation qualitative\n",
        "                        best_sim = results[0]['similarity']\n",
        "                        if best_sim >= 0.7:\n",
        "                            print(f\"🌟 EXCELLENTE correspondance! (sim: {best_sim:.4f})\")\n",
        "                        elif best_sim >= 0.5:\n",
        "                            print(f\"👍 BONNE correspondance (sim: {best_sim:.4f})\")\n",
        "                        elif best_sim >= 0.3:\n",
        "                            print(f\"⚠️ Correspondance MOYENNE (sim: {best_sim:.4f})\")\n",
        "                        else:\n",
        "                            print(f\"❌ Correspondance FAIBLE (sim: {best_sim:.4f})\")\n",
        "                        \n",
        "                    else:\n",
        "                        print(\"❌ Aucun résultat trouvé (similarité trop faible)\")\n",
        "                        print(\"   Essayez de réduire min_similarity ou vérifiez l'image\")\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Erreur lors du test: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "            \n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"✅ TESTS AVEC IMAGES CUSTOM TERMINÉS\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "        else:\n",
        "            print(f\"❌ Aucune image trouvée dans {test_images_dir}\")\n",
        "            print(f\"   Extensions supportées: {image_extensions}\")\n",
        "    else:\n",
        "        print(f\"❌ Dossier {test_images_dir} non trouvé!\")\n",
        "        print(\"   Créez le dossier et ajoutez-y des images de recettes pour les tests\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ Système de récupération non initialisé!\")\n",
        "    print(\"   Initialisez d'abord le système avec un modèle entraîné.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎉 RÉSUMÉ FINAL - FINE-TUNING COMPLET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"🎉 RÉSUMÉ FINAL DU NOTEBOOK FINE-TUNING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n🔥 CONFIGURATION FINE-TUNING:\")\n",
        "print(f\"   📐 Taille image: {CONFIG_FT['IMG_SIZE']}x{CONFIG_FT['IMG_SIZE']}\")\n",
        "print(f\"   🧠 Dimension embedding: {CONFIG_FT['EMBEDDING_DIM']}\")\n",
        "print(f\"   📚 Batch size: {CONFIG_FT['BATCH_SIZE']}\")\n",
        "print(f\"   📈 Learning rate: {CONFIG_FT['FINETUNE_LR']}\")\n",
        "print(f\"   🎯 Marge triplet: {CONFIG_FT['MARGIN']}\")\n",
        "print(f\"   ❄️ Couches gelées: {CONFIG_FT['FREEZE_LAYERS']}\")\n",
        "print(f\"   🔥 Couches dégelées: 20 dernières couches\")\n",
        "\n",
        "print(f\"\\n🏗️ ARCHITECTURE:\")\n",
        "print(f\"   🖼️ Base: EfficientNetB0 pré-entraîné\")\n",
        "print(f\"   🧠 Embedding: Couche dense {CONFIG_FT['EMBEDDING_DIM']}D + L2 norm\")\n",
        "print(f\"   🎯 Loss: Triplet Loss avec hard negative mining\")\n",
        "print(f\"   📊 Augmentation: Conservative pour fine-tuning\")\n",
        "\n",
        "print(f\"\\n📊 DONNÉES:\")\n",
        "if 'recipes_with_images' in globals():\n",
        "    print(f\"   📋 Recettes totales: {len(recipes_with_images)}\")\n",
        "    print(f\"   📸 Images disponibles: {len(recipes_with_images)}\")\n",
        "    print(f\"   🔄 Split: {int((1-CONFIG_FT['VALIDATION_SPLIT'])*100)}% train / {int(CONFIG_FT['VALIDATION_SPLIT']*100)}% validation\")\n",
        "else:\n",
        "    print(\"   ❌ Données non chargées\")\n",
        "\n",
        "print(f\"\\n🤖 MODÈLE:\")\n",
        "model_path_ft = f\"ft/{CONFIG_FT['MODEL_NAME']}\"\n",
        "if os.path.exists(model_path_ft):\n",
        "    print(f\"   ✅ Modèle entraîné: {model_path_ft}\")\n",
        "    print(f\"   💾 Taille: {os.path.getsize(model_path_ft) / (1024*1024):.1f} MB\")\n",
        "else:\n",
        "    print(f\"   ❌ Modèle non trouvé: {model_path_ft}\")\n",
        "\n",
        "print(f\"\\n📊 SYSTÈME DE RÉCUPÉRATION:\")\n",
        "if 'retrieval_system_ft' in globals() and retrieval_system_ft is not None:\n",
        "    print(f\"   ✅ Système initialisé\")\n",
        "    if retrieval_system_ft.embeddings_db is not None:\n",
        "        print(f\"   📊 Base d'embeddings: {retrieval_system_ft.embeddings_db.shape}\")\n",
        "        print(f\"   📋 Recettes indexées: {len(retrieval_system_ft.recipes_df)}\")\n",
        "    else:\n",
        "        print(f\"   ⚠️ Base d'embeddings non construite\")\n",
        "else:\n",
        "    print(f\"   ❌ Système non initialisé\")\n",
        "\n",
        "print(f\"\\n📈 PERFORMANCE ATTENDUE:\")\n",
        "print(f\"   🎯 Objectif Accuracy: >95%\")\n",
        "print(f\"   📈 Objectif Pos Similarity: >0.6\")\n",
        "print(f\"   📉 Objectif Neg Similarity: <0.3\")\n",
        "print(f\"   📏 Objectif Gap Pos-Neg: >0.3\")\n",
        "\n",
        "print(f\"\\n🧪 TESTS DISPONIBLES:\")\n",
        "print(f\"   🎲 Images aléatoires du dataset\")\n",
        "print(f\"   🖼️ Images custom du dossier test_recipes/\")\n",
        "print(f\"   📊 Visualisation des résultats\")\n",
        "\n",
        "print(f\"\\n💡 UTILISATION:\")\n",
        "print(f\"   1️⃣ Entraîner: train_fine_tuning()\")\n",
        "print(f\"   2️⃣ Initialiser: RecipeImageRetrievalFT()\")\n",
        "print(f\"   3️⃣ Rechercher: search_similar_recipes()\")\n",
        "print(f\"   4️⃣ Visualiser: plot_training_results_ft()\")\n",
        "\n",
        "print(f\"\\n🔄 AMÉLIORATIONS PAR RAPPORT AU TRANSFER LEARNING:\")\n",
        "print(f\"   🔥 Fine-tuning des 20 dernières couches\")\n",
        "print(f\"   📈 Learning rate adapté (1e-5)\")\n",
        "print(f\"   🛡️ Augmentation conservative\")\n",
        "print(f\"   ⚖️ Weight decay pour régularisation\")\n",
        "print(f\"   📊 Meilleure adaptation au domaine des recettes\")\n",
        "\n",
        "print(f\"\\n=\" * 80)\n",
        "print(f\"🎯 NOTEBOOK FINE-TUNING COMPLET ET OPÉRATIONNEL!\")\n",
        "print(f\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "itadaki_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
