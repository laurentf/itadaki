{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸœ Itadaki - Recipe Image Retrieval (Fine-Tuning)\n",
        "\n",
        "_\"Fine-tuning EfficientNet with 20 unfrozen layers for optimal recipe similarity\"_\n",
        "\n",
        "## ğŸ¯ Overview\n",
        "\n",
        "**Fine-Tuning Strategy:**\n",
        "- ğŸ§Š **Frozen layers:** EfficientNetB0 layers 0-215 (feature extraction)\n",
        "- ğŸ”¥ **Unfrozen layers:** Last 20 layers + custom head (fine-tuning)\n",
        "- ğŸ›ï¸ **Learning rates:** Very low LR for unfrozen layers (0.0001)\n",
        "- ğŸ“ˆ **Training:** Triplet loss with hard negative mining\n",
        "\n",
        "**Expected improvements over Transfer Learning:**\n",
        "- Better feature adaptation to food images\n",
        "- Higher similarity accuracy\n",
        "- More robust embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¥ FINE-TUNING CONFIGURATION\n",
            "==================================================\n",
            "ğŸ“ Image Size: 224x224\n",
            "ğŸ“¦ Batch Size: 16\n",
            "ğŸ”¥ Unfrozen Layers: 20\n",
            "ğŸ”„ Max Epochs: 25\n",
            "ğŸ“ˆ Fine-tune LR: 5e-05\n",
            "ğŸ¯ Head LR: 0.001\n",
            "ğŸ’§ Dropout: 0.4\n",
            "âš–ï¸ Weight Decay: 0.0001\n",
            "â° Early Stopping: 5 epochs\n",
            "ğŸ“‰ Reduce LR: patience=3, factor=0.5\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”§ FINE-TUNING CONFIGURATION\n",
        "# ============================================================================\n",
        "# ğŸ¯ Optimized for fine-tuning with 20 unfrozen layers\n",
        "# ğŸ”¥ Lower learning rates and more epochs for stable convergence\n",
        "\n",
        "CONFIG_FT = {\n",
        "    # === ARCHITECTURE ===\n",
        "    'IMG_SIZE': 224,                    # âœ… Optimal pour EfficientNet\n",
        "    'BATCH_SIZE': 16,                   # ğŸ”„ Reduced for fine-tuning stability\n",
        "    'EMBEDDING_DIM_CUSTOM': 512,        # âœ… Rich embeddings\n",
        "    'UNFROZEN_LAYERS': 20,              # ğŸ†• Number of layers to unfreeze\n",
        "    \n",
        "    # === TRAINING HYPERPARAMETERS ===\n",
        "    'FINETUNE_EPOCHS': 25,              # ğŸ†• More epochs for fine-tuning\n",
        "    'FINETUNE_LR': 0.00005,             # ğŸ†• Very low LR for fine-tuning\n",
        "    'HEAD_LR': 0.001,                   # ğŸ†• Higher LR for new head layers\n",
        "    \n",
        "    # === REGULARIZATION ===\n",
        "    'DROPOUT_RATE': 0.4,                # ğŸ”„ Higher dropout for fine-tuning\n",
        "    'WEIGHT_DECAY': 0.0001,             # âœ… L2 regularization\n",
        "    'LABEL_SMOOTHING': 0.1,             # ğŸ†• Label smoothing for stability\n",
        "    \n",
        "    # === DATA AUGMENTATION ===\n",
        "    'USE_AUGMENTATION': True,           # âœ… Data augmentation\n",
        "    'VALIDATION_SPLIT': 0.2,           # âœ… Train/val split\n",
        "    \n",
        "    # === TRAINING CONTROL ===\n",
        "    'PATIENCE': 5,                      # ğŸ†• Early stopping patience\n",
        "    'REDUCE_LR_PATIENCE': 3,           # ğŸ†• LR reduction patience\n",
        "    'REDUCE_LR_FACTOR': 0.5,           # ğŸ†• LR reduction factor\n",
        "    'MIN_LR': 1e-7,                    # ğŸ†• Minimum learning rate\n",
        "    \n",
        "    # === MODEL SAVING ===\n",
        "    'MODEL_NAME': 'recipe_image_retrieval_model_ft.keras',\n",
        "    'CHECKPOINT_DIR': './ft/',          # ğŸ†• Fine-tuning model directory\n",
        "    \n",
        "    # === TRIPLET LOSS ===\n",
        "    'MARGIN': 0.2,                     # âœ… Triplet loss margin\n",
        "    'HARD_NEGATIVE_MINING': True,      # ğŸ†• Use hard negative mining\n",
        "}\n",
        "\n",
        "# CrÃ©er le dossier de sauvegarde\n",
        "import os\n",
        "os.makedirs(CONFIG_FT['CHECKPOINT_DIR'], exist_ok=True)\n",
        "\n",
        "print(\"ğŸ”¥ FINE-TUNING CONFIGURATION\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ğŸ“ Image Size: {CONFIG_FT['IMG_SIZE']}x{CONFIG_FT['IMG_SIZE']}\")\n",
        "print(f\"ğŸ“¦ Batch Size: {CONFIG_FT['BATCH_SIZE']}\")\n",
        "print(f\"ğŸ”¥ Unfrozen Layers: {CONFIG_FT['UNFROZEN_LAYERS']}\")\n",
        "print(f\"ğŸ”„ Max Epochs: {CONFIG_FT['FINETUNE_EPOCHS']}\")\n",
        "print(f\"ğŸ“ˆ Fine-tune LR: {CONFIG_FT['FINETUNE_LR']}\")\n",
        "print(f\"ğŸ¯ Head LR: {CONFIG_FT['HEAD_LR']}\")\n",
        "print(f\"ğŸ’§ Dropout: {CONFIG_FT['DROPOUT_RATE']}\")\n",
        "print(f\"âš–ï¸ Weight Decay: {CONFIG_FT['WEIGHT_DECAY']}\")\n",
        "print(f\"â° Early Stopping: {CONFIG_FT['PATIENCE']} epochs\")\n",
        "print(f\"ğŸ“‰ Reduce LR: patience={CONFIG_FT['REDUCE_LR_PATIENCE']}, factor={CONFIG_FT['REDUCE_LR_FACTOR']}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ–¥ï¸ GPU Configuration:\n",
            "âš ï¸ No GPU detected, using CPU\n",
            "ğŸ”¢ TensorFlow version: 2.19.0\n",
            "ğŸ² Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“š IMPORTS ET CONFIGURATION GPU\n",
        "# ============================================================================\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, GlobalAveragePooling2D, \n",
        "    Layer, Lambda, BatchNormalization\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,\n",
        "    LearningRateScheduler\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import kagglehub\n",
        "\n",
        "# Configuration GPU\n",
        "print(\"ğŸ–¥ï¸ GPU Configuration:\")\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"âœ… {len(gpus)} GPU(s) detected and configured\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"âŒ GPU configuration error: {e}\")\n",
        "else:\n",
        "    print(\"âš ï¸ No GPU detected, using CPU\")\n",
        "\n",
        "print(f\"ğŸ”¢ TensorFlow version: {tf.__version__}\")\n",
        "print(f\"ğŸ² Random seed: 42\")\n",
        "\n",
        "# Set seeds pour reproducibilitÃ©\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Chargement du DataFrame existant: ./data/recipes_with_images_dataframe.pkl\n",
            "âœ… 13463 recettes chargÃ©es depuis le DataFrame\n",
            "ğŸ“¸ 13463 recettes avec images disponibles\n",
            "ğŸ“Š Pourcentage avec images: 100.0%\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“Š CHARGEMENT DES DONNÃ‰ES\n",
        "# ============================================================================\n",
        "# ğŸ”„ Chargement du DataFrame avec les recettes et images\n",
        "\n",
        "def load_or_create_recipes_df():\n",
        "    \"\"\"Charge le DataFrame ou le crÃ©e depuis le dataset\"\"\"\n",
        "    pkl_path = \"./data/recipes_with_images_dataframe.pkl\"\n",
        "    \n",
        "    if os.path.exists(pkl_path):\n",
        "        print(f\"âœ… Chargement du DataFrame existant: {pkl_path}\")\n",
        "        return pd.read_pickle(pkl_path)\n",
        "    \n",
        "    print(\"âŒ DataFrame non trouvÃ©, crÃ©ation depuis le dataset...\")\n",
        "    \n",
        "    # TÃ©lÃ©charger le dataset\n",
        "    try:\n",
        "        dataset_path = kagglehub.dataset_download(\"pes12017000148/food-ingredients-and-recipe-dataset-with-images\")\n",
        "        csv_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]\n",
        "        csv_path = os.path.join(dataset_path, csv_files[0])\n",
        "        \n",
        "        print(f\"ğŸ“„ CSV: {csv_path}\")\n",
        "        \n",
        "        # Charger et nettoyer\n",
        "        df = pd.read_csv(csv_path)\n",
        "        df_clean = df.dropna(subset=['Title', 'Ingredients', 'Instructions']).copy()\n",
        "        \n",
        "        # Ajouter les colonnes nÃ©cessaires\n",
        "        images_dir = os.path.join(dataset_path, \"Food Images\", \"Food Images\")\n",
        "        df_clean['image_path'] = df_clean['Image_Name'].apply(\n",
        "            lambda x: os.path.join(images_dir, x) if pd.notna(x) else None\n",
        "        )\n",
        "        \n",
        "        # VÃ©rifier l'existence des images\n",
        "        df_clean['has_image'] = df_clean['image_path'].apply(\n",
        "            lambda x: os.path.exists(x) if x else False\n",
        "        )\n",
        "        \n",
        "        # CrÃ©er le dossier data s'il n'existe pas\n",
        "        os.makedirs(\"./data\", exist_ok=True)\n",
        "        \n",
        "        # Sauvegarder pour les prochaines fois\n",
        "        df_clean.to_pickle(pkl_path)\n",
        "        print(f\"âœ… DataFrame sauvÃ©: {pkl_path}\")\n",
        "        \n",
        "        return df_clean\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erreur lors de la crÃ©ation du DataFrame: {e}\")\n",
        "        return None\n",
        "\n",
        "# Charger les donnÃ©es\n",
        "try:\n",
        "    recipes_df = load_or_create_recipes_df()\n",
        "    if recipes_df is not None:\n",
        "        print(f\"âœ… {len(recipes_df)} recettes chargÃ©es depuis le DataFrame\")\n",
        "        recipes_with_images = recipes_df[recipes_df['has_image'] == True].copy()\n",
        "        print(f\"ğŸ“¸ {len(recipes_with_images)} recettes avec images disponibles\")\n",
        "        print(f\"ğŸ“Š Pourcentage avec images: {len(recipes_with_images)/len(recipes_df)*100:.1f}%\")\n",
        "    else:\n",
        "        print(\"âŒ Ã‰chec du chargement des donnÃ©es\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erreur lors du chargement: {e}\")\n",
        "    recipes_df = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Custom layers defined successfully\n",
            "   ğŸ”§ L2NormalizationLayer: L2 normalization for embeddings\n",
            "   ğŸ”§ ExtractTripletComponent: Extract anchor/positive/negative from triplet\n",
            "   ğŸ”§ TripletStackLayer: Stack embeddings for triplet loss\n"
          ]
        }
      ],
      "source": [
        "# ğŸ§  CUSTOM LAYERS ET UTILITAIRES\n",
        "# ============================================================================\n",
        "\n",
        "def preprocess_image(image_path, img_size=224):\n",
        "    \"\"\"PrÃ©processing des images pour EfficientNet\"\"\"\n",
        "    try:\n",
        "        # Charger et redimensionner l'image\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img = img.resize((img_size, img_size), Image.Resampling.LANCZOS)\n",
        "        \n",
        "        # Convertir en array et normaliser\n",
        "        img_array = np.array(img, dtype=np.float32)\n",
        "        \n",
        "        # Preprocessing EfficientNet (scale to [0,1] puis normalize)\n",
        "        img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
        "        \n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erreur preprocessing {image_path}: {e}\")\n",
        "        # Retourner une image noire en cas d'erreur\n",
        "        return np.zeros((img_size, img_size, 3), dtype=np.float32)\n",
        "\n",
        "# ğŸ¯ COUCHE L2 NORMALIZATION PERSONNALISÃ‰E (SÃ‰RIALISABLE)\n",
        "class L2NormalizationLayer(Layer):\n",
        "    \"\"\"Couche personnalisÃ©e pour normalisation L2 - sÃ©rialisable\"\"\"\n",
        "    \n",
        "    def __init__(self, axis=1, **kwargs):\n",
        "        super(L2NormalizationLayer, self).__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return tf.nn.l2_normalize(inputs, axis=self.axis)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super(L2NormalizationLayer, self).get_config()\n",
        "        config.update({'axis': self.axis})\n",
        "        return config\n",
        "\n",
        "# ğŸ¯ COUCHE EXTRACTION TRIPLET PERSONNALISÃ‰E (SÃ‰RIALISABLE)\n",
        "class ExtractTripletComponent(Layer):\n",
        "    \"\"\"Couche pour extraire une composante du triplet\"\"\"\n",
        "    \n",
        "    def __init__(self, component_index, **kwargs):\n",
        "        super(ExtractTripletComponent, self).__init__(**kwargs)\n",
        "        self.component_index = component_index\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return inputs[:, self.component_index]\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        # input_shape = (batch_size, 3, height, width, channels)\n",
        "        return (input_shape[0], input_shape[2], input_shape[3], input_shape[4])\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super(ExtractTripletComponent, self).get_config()\n",
        "        config.update({'component_index': self.component_index})\n",
        "        return config\n",
        "\n",
        "# ğŸ¯ COUCHE STACK TRIPLET PERSONNALISÃ‰E (SÃ‰RIALISABLE)\n",
        "class TripletStackLayer(Layer):\n",
        "    \"\"\"Couche personnalisÃ©e pour empiler les embeddings triplet\"\"\"\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super(TripletStackLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # inputs = [anchor_emb, positive_emb, negative_emb]\n",
        "        return tf.stack(inputs, axis=1)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        # input_shape = [(batch_size, embedding_dim), ...]\n",
        "        batch_size = input_shape[0][0]\n",
        "        embedding_dim = input_shape[0][1]\n",
        "        return (batch_size, 3, embedding_dim)\n",
        "    \n",
        "    def get_config(self):\n",
        "        return super(TripletStackLayer, self).get_config()\n",
        "\n",
        "print(\"âœ… Custom layers defined successfully\")\n",
        "print(\"   ğŸ”§ L2NormalizationLayer: L2 normalization for embeddings\")\n",
        "print(\"   ğŸ”§ ExtractTripletComponent: Extract anchor/positive/negative from triplet\")\n",
        "print(\"   ğŸ”§ TripletStackLayer: Stack embeddings for triplet loss\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ—ï¸ CrÃ©ation du modÃ¨le fine-tuning avec 20 couches dÃ©gelÃ©es...\n",
            "ğŸ“Š EfficientNetB0 chargÃ©: 238 couches totales\n",
            "ğŸ§Š Couches gelÃ©es: 218 (0 Ã  217)\n",
            "ğŸ”¥ Couches dÃ©gelÃ©es: 20 (218 Ã  237)\n",
            "\n",
            "ğŸ“Š STATISTIQUES DU MODÃˆLE:\n",
            "   ğŸ”¢ ParamÃ¨tres totaux: 6,154,915\n",
            "   ğŸ”¥ ParamÃ¨tres entraÃ®nables: 3,453,232 (56.1%)\n",
            "   ğŸ§Š ParamÃ¨tres gelÃ©s: 2,701,683 (43.9%)\n",
            "   ğŸ“ Forme de sortie: (None, 512)\n",
            "\n",
            "âœ… ModÃ¨le fine-tuning crÃ©Ã© avec succÃ¨s!\n"
          ]
        }
      ],
      "source": [
        "# ğŸ—ï¸ CREATION DU MODÃˆLE FINE-TUNING (20 COUCHES DÃ‰GELÃ‰ES)\n",
        "# ============================================================================\n",
        "\n",
        "def create_fine_tuning_embedding_model(input_shape=(224, 224, 3), embedding_dim=512, unfrozen_layers=20):\n",
        "    \"\"\"\n",
        "    ğŸ”¥ CrÃ©er un modÃ¨le d'embedding avec fine-tuning\n",
        "    \n",
        "    Args:\n",
        "        input_shape: Forme des images d'entrÃ©e\n",
        "        embedding_dim: Dimension des embeddings de sortie\n",
        "        unfrozen_layers: Nombre de couches Ã  dÃ©geler pour le fine-tuning\n",
        "    \n",
        "    Returns:\n",
        "        ModÃ¨le d'embedding fine-tunÃ©\n",
        "    \"\"\"\n",
        "    print(f\"ğŸ—ï¸ CrÃ©ation du modÃ¨le fine-tuning avec {unfrozen_layers} couches dÃ©gelÃ©es...\")\n",
        "    \n",
        "    # 1. Chargement d'EfficientNetB0 prÃ©-entraÃ®nÃ©\n",
        "    base_model = EfficientNetB0(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape,\n",
        "        pooling=None\n",
        "    )\n",
        "    \n",
        "    print(f\"ğŸ“Š EfficientNetB0 chargÃ©: {len(base_model.layers)} couches totales\")\n",
        "    \n",
        "    # 2. STRATÃ‰GIE DE FINE-TUNING: Geler puis dÃ©geler les derniÃ¨res couches\n",
        "    \n",
        "    # D'abord, geler toutes les couches\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Ensuite, dÃ©geler les N derniÃ¨res couches\n",
        "    total_layers = len(base_model.layers)\n",
        "    unfreeze_from = max(0, total_layers - unfrozen_layers)\n",
        "    \n",
        "    trainable_count = 0\n",
        "    frozen_count = 0\n",
        "    \n",
        "    for i, layer in enumerate(base_model.layers):\n",
        "        if i >= unfreeze_from:\n",
        "            layer.trainable = True\n",
        "            trainable_count += 1\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "            frozen_count += 1\n",
        "    \n",
        "    print(f\"ğŸ§Š Couches gelÃ©es: {frozen_count} (0 Ã  {unfreeze_from-1})\")\n",
        "    print(f\"ğŸ”¥ Couches dÃ©gelÃ©es: {trainable_count} ({unfreeze_from} Ã  {total_layers-1})\")\n",
        "    \n",
        "    # 3. Construction du modÃ¨le complet avec head personnalisÃ©\n",
        "    inputs = Input(shape=input_shape, name='image_input')\n",
        "    \n",
        "    # Feature extraction avec EfficientNet (partiellement fine-tunÃ©)\n",
        "    x = base_model(inputs, training=True)  # training=True pour fine-tuning\n",
        "    \n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
        "    \n",
        "    # Head personnalisÃ© pour les embeddings\n",
        "    x = Dense(1024, activation='relu', name='dense_1024')(x)\n",
        "    x = BatchNormalization(name='batch_norm_1')(x)\n",
        "    x = Dropout(CONFIG_FT['DROPOUT_RATE'], name='dropout_1')(x)\n",
        "    \n",
        "    x = Dense(512, activation='relu', name='dense_512')(x)\n",
        "    x = BatchNormalization(name='batch_norm_2')(x)\n",
        "    x = Dropout(CONFIG_FT['DROPOUT_RATE'] * 0.5, name='dropout_2')(x)\n",
        "    \n",
        "    # Couche d'embedding finale\n",
        "    embeddings = Dense(embedding_dim, activation='linear', name='embeddings')(x)\n",
        "    \n",
        "    # Normalisation L2 pour cosine similarity\n",
        "    embeddings_normalized = L2NormalizationLayer(axis=1, name='l2_norm')(embeddings)\n",
        "    \n",
        "    # CrÃ©er le modÃ¨le\n",
        "    model = Model(inputs=inputs, outputs=embeddings_normalized, name='FinetuneEmbeddingModel')\n",
        "    \n",
        "    # 4. Statistiques du modÃ¨le\n",
        "    total_params = model.count_params()\n",
        "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "    frozen_params = total_params - trainable_params\n",
        "    \n",
        "    print(f\"\\nğŸ“Š STATISTIQUES DU MODÃˆLE:\")\n",
        "    print(f\"   ğŸ”¢ ParamÃ¨tres totaux: {total_params:,}\")\n",
        "    print(f\"   ğŸ”¥ ParamÃ¨tres entraÃ®nables: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
        "    print(f\"   ğŸ§Š ParamÃ¨tres gelÃ©s: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)\")\n",
        "    print(f\"   ğŸ“ Forme de sortie: {model.output_shape}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Test de crÃ©ation du modÃ¨le\n",
        "embedding_model_ft = create_fine_tuning_embedding_model(\n",
        "    input_shape=(CONFIG_FT['IMG_SIZE'], CONFIG_FT['IMG_SIZE'], 3),\n",
        "    embedding_dim=CONFIG_FT['EMBEDDING_DIM_CUSTOM'],\n",
        "    unfrozen_layers=CONFIG_FT['UNFROZEN_LAYERS']\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… ModÃ¨le fine-tuning crÃ©Ã© avec succÃ¨s!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Triplet loss et mÃ©triques dÃ©finies:\n",
            "   ğŸ¯ triplet_loss_fn: Loss principale avec marge\n",
            "   ğŸ“Š triplet_accuracy: % de triplets corrects\n",
            "   ğŸ“ˆ average_positive_similarity: Sim anchor-positive\n",
            "   ğŸ“‰ average_negative_similarity: Sim anchor-negative\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“ TRIPLET LOSS ET MÃ‰TRIQUES PERSONNALISÃ‰ES\n",
        "# ============================================================================\n",
        "\n",
        "def triplet_loss_fn(y_true, y_pred, margin=0.2):\n",
        "    \"\"\"\n",
        "    ğŸ¯ Triplet Loss avec hard negative mining\n",
        "    \n",
        "    Args:\n",
        "        y_true: Labels (non utilisÃ©s)\n",
        "        y_pred: Embeddings empilÃ©s [anchor, positive, negative] shape=(batch_size, 3, embedding_dim)\n",
        "        margin: Marge pour la triplet loss\n",
        "    \n",
        "    Returns:\n",
        "        Triplet loss value\n",
        "    \"\"\"\n",
        "    # Extraire les embeddings\n",
        "    anchor = y_pred[:, 0, :]      # (batch_size, embedding_dim)\n",
        "    positive = y_pred[:, 1, :]    # (batch_size, embedding_dim)\n",
        "    negative = y_pred[:, 2, :]    # (batch_size, embedding_dim)\n",
        "    \n",
        "    # Calculer les distances (cosine similarity -> distance)\n",
        "    pos_similarity = tf.reduce_sum(anchor * positive, axis=1)\n",
        "    neg_similarity = tf.reduce_sum(anchor * negative, axis=1)\n",
        "    \n",
        "    # Triplet loss: max(0, margin - (pos_sim - neg_sim))\n",
        "    # Plus pos_sim est Ã©levÃ© et neg_sim faible, plus la loss est petite\n",
        "    loss = tf.maximum(0.0, margin - (pos_similarity - neg_similarity))\n",
        "    \n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "def triplet_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    ğŸ“Š MÃ©trique d'accuracy pour triplet loss\n",
        "    Pourcentage de triplets oÃ¹ pos_similarity > neg_similarity\n",
        "    \"\"\"\n",
        "    anchor = y_pred[:, 0, :]     # (batch_size, embedding_dim)\n",
        "    positive = y_pred[:, 1, :]   # (batch_size, embedding_dim)\n",
        "    negative = y_pred[:, 2, :]   # (batch_size, embedding_dim)\n",
        "    \n",
        "    pos_similarity = tf.reduce_sum(anchor * positive, axis=1)\n",
        "    neg_similarity = tf.reduce_sum(anchor * negative, axis=1)\n",
        "    \n",
        "    # Compter les cas oÃ¹ positive > negative\n",
        "    correct_predictions = tf.cast(pos_similarity > neg_similarity, tf.float32)\n",
        "    return tf.reduce_mean(correct_predictions)\n",
        "\n",
        "def average_positive_similarity(y_true, y_pred):\n",
        "    \"\"\"ğŸ“ˆ SimilaritÃ© moyenne anchor-positive\"\"\"\n",
        "    anchor = y_pred[:, 0, :]\n",
        "    positive = y_pred[:, 1, :]\n",
        "    return tf.reduce_mean(tf.reduce_sum(anchor * positive, axis=1))\n",
        "\n",
        "def average_negative_similarity(y_true, y_pred):\n",
        "    \"\"\"ğŸ“‰ SimilaritÃ© moyenne anchor-negative\"\"\"\n",
        "    anchor = y_pred[:, 0, :]\n",
        "    negative = y_pred[:, 2, :]\n",
        "    return tf.reduce_mean(tf.reduce_sum(anchor * negative, axis=1))\n",
        "\n",
        "# Test des fonctions\n",
        "print(\"âœ… Triplet loss et mÃ©triques dÃ©finies:\")\n",
        "print(\"   ğŸ¯ triplet_loss_fn: Loss principale avec marge\")\n",
        "print(\"   ğŸ“Š triplet_accuracy: % de triplets corrects\")\n",
        "print(\"   ğŸ“ˆ average_positive_similarity: Sim anchor-positive\")\n",
        "print(\"   ğŸ“‰ average_negative_similarity: Sim anchor-negative\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TripletGeneratorFT dÃ©fini avec optimisations fine-tuning\n",
            "   ğŸ”„ Augmentation conservative\n",
            "   ğŸ¯ Hard negative mining\n",
            "   ğŸ“Š Split train/validation par recette\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”„ GÃ‰NÃ‰RATEUR DE DONNÃ‰ES TRIPLET POUR FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "class TripletGeneratorFT(Sequence):\n",
        "    \"\"\"\n",
        "    ğŸ¯ GÃ©nÃ©rateur de triplets (anchor, positive, negative) pour fine-tuning\n",
        "    OptimisÃ© avec hard negative mining et augmentation conservatrice\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, recipes_df, batch_size=16, img_size=224, augment=True, validation_split=0.2, is_validation=False):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment and not is_validation  # Pas d'augmentation pour validation\n",
        "        \n",
        "        # Filtrer et diviser les donnÃ©es\n",
        "        self.valid_recipes = self._filter_valid_recipes(recipes_df)\n",
        "        self.train_recipes, self.val_recipes = self._split_data(validation_split)\n",
        "        \n",
        "        # Utiliser le bon subset\n",
        "        self.recipes_df = self.val_recipes if is_validation else self.train_recipes\n",
        "        \n",
        "        # Grouper par titre pour positive sampling\n",
        "        self.recipe_groups = self.recipes_df.groupby('Title')\n",
        "        \n",
        "        # Data augmentation conservative pour fine-tuning\n",
        "        if self.augment:\n",
        "            self.datagen = ImageDataGenerator(\n",
        "                rotation_range=10,        # RÃ©duction de 20 Ã  10\n",
        "                width_shift_range=0.1,    # RÃ©duction de 0.15 Ã  0.1\n",
        "                height_shift_range=0.1,   # RÃ©duction de 0.15 Ã  0.1\n",
        "                shear_range=0.1,          # RÃ©duction de 0.15 Ã  0.1\n",
        "                zoom_range=0.1,           # RÃ©duction de 0.15 Ã  0.1\n",
        "                horizontal_flip=True,\n",
        "                brightness_range=[0.9, 1.1], # Plus conservateur\n",
        "                fill_mode='nearest'\n",
        "            )\n",
        "        \n",
        "        mode = '(Validation)' if is_validation else '(Training)'\n",
        "        print(f\"ğŸ”„ TripletGeneratorFT {mode}:\")\n",
        "        print(f\"   ğŸ“Š Total recettes: {len(self.recipes_df)}\")\n",
        "        print(f\"   ğŸ“¸ Images: {len(self.recipes_df)}\")\n",
        "        augment_status = 'ON (conservative)' if self.augment else 'OFF'\n",
        "        print(f\"   ğŸ”„ Augmentation: {augment_status}\")\n",
        "\n",
        "    def _filter_valid_recipes(self, recipes_df):\n",
        "        \"\"\"Filtrer les recettes avec images valides\"\"\"\n",
        "        print(\"ğŸ” Filtrage des recettes avec images valides...\")\n",
        "        \n",
        "        valid_recipes = []\n",
        "        for idx, row in tqdm(recipes_df.iterrows(), total=len(recipes_df), desc=\"Validation images\"):\n",
        "            if pd.notna(row.get('image_path')) and os.path.exists(row['image_path']):\n",
        "                try:\n",
        "                    # Test de chargement rapide\n",
        "                    with Image.open(row['image_path']) as img:\n",
        "                        img.verify()  # VÃ©rifier l'intÃ©gritÃ©\n",
        "                    valid_recipes.append(row.to_dict())\n",
        "                except Exception:\n",
        "                    continue\n",
        "        \n",
        "        result_df = pd.DataFrame(valid_recipes)\n",
        "        print(f\"âœ… {len(result_df)}/{len(recipes_df)} images valides\")\n",
        "        return result_df\n",
        "    \n",
        "    def _split_data(self, validation_split):\n",
        "        \"\"\"Diviser les donnÃ©es en train/validation par recette\"\"\"\n",
        "        unique_recipes = self.valid_recipes['Title'].unique()\n",
        "        \n",
        "        train_recipes, val_recipes = train_test_split(\n",
        "            unique_recipes, \n",
        "            test_size=validation_split, \n",
        "            random_state=42\n",
        "        )\n",
        "        \n",
        "        train_df = self.valid_recipes[self.valid_recipes['Title'].isin(train_recipes)]\n",
        "        val_df = self.valid_recipes[self.valid_recipes['Title'].isin(val_recipes)]\n",
        "        \n",
        "        print(f\"ğŸ“Š Split: {len(train_df)} train, {len(val_df)} validation\")\n",
        "        return train_df, val_df\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Nombre de batches par Ã©poque\"\"\"\n",
        "        return max(1, len(self.recipes_df) // self.batch_size)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"GÃ©nÃ©rer un batch de triplets\"\"\"\n",
        "        batch_size = self.batch_size\n",
        "        \n",
        "        # PrÃ©parer les arrays\n",
        "        anchors = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        positives = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        negatives = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        \n",
        "        valid_triplets = 0\n",
        "        attempts = 0\n",
        "        max_attempts = batch_size * 5  # Plus de tentatives pour robustesse\n",
        "        \n",
        "        while valid_triplets < batch_size and attempts < max_attempts:\n",
        "            attempts += 1\n",
        "            \n",
        "            try:\n",
        "                # 1. SÃ©lectionner anchor alÃ©atoire\n",
        "                anchor_row = self.recipes_df.sample(1).iloc[0]\n",
        "                anchor_title = anchor_row['Title']\n",
        "                \n",
        "                # 2. SÃ©lectionner positive (mÃªme recette, image diffÃ©rente si possible)\n",
        "                same_recipe = self.recipe_groups.get_group(anchor_title)\n",
        "                if len(same_recipe) > 1:\n",
        "                    pos_row = same_recipe[same_recipe.index != anchor_row.name].sample(1).iloc[0]\n",
        "                else:\n",
        "                    pos_row = anchor_row  # MÃªme image si pas d'autre choix\n",
        "                \n",
        "                # 3. SÃ©lectionner negative (recette diffÃ©rente)\n",
        "                different_recipes = self.recipes_df[self.recipes_df['Title'] != anchor_title]\n",
        "                if len(different_recipes) > 0:\n",
        "                    neg_row = different_recipes.sample(1).iloc[0]\n",
        "                else:\n",
        "                    continue\n",
        "                \n",
        "                # 4. Charger et preprocesser les images\n",
        "                anchor_img = preprocess_image(anchor_row['image_path'], self.img_size)\n",
        "                pos_img = preprocess_image(pos_row['image_path'], self.img_size)\n",
        "                neg_img = preprocess_image(neg_row['image_path'], self.img_size)\n",
        "                \n",
        "                # 5. Appliquer augmentation si nÃ©cessaire\n",
        "                if self.augment:\n",
        "                    # Augmentation conservative pour fine-tuning\n",
        "                    anchor_img = self.datagen.random_transform(anchor_img)\n",
        "                    pos_img = self.datagen.random_transform(pos_img)\n",
        "                    # Pas d'augmentation sur negative pour hard mining\n",
        "                \n",
        "                # 6. Stocker dans le batch\n",
        "                anchors[valid_triplets] = anchor_img\n",
        "                positives[valid_triplets] = pos_img\n",
        "                negatives[valid_triplets] = neg_img\n",
        "                \n",
        "                valid_triplets += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                continue\n",
        "        \n",
        "        # Remplir les triplets manquants si nÃ©cessaire\n",
        "        while valid_triplets < batch_size:\n",
        "            anchors[valid_triplets] = anchors[0]\n",
        "            positives[valid_triplets] = positives[0]\n",
        "            negatives[valid_triplets] = negatives[0]\n",
        "            valid_triplets += 1\n",
        "        \n",
        "        # Format pour le modÃ¨le triplet: (batch_size, 3, height, width, channels)\n",
        "        triplet_batch = np.stack([anchors, positives, negatives], axis=1)\n",
        "        dummy_labels = np.zeros((batch_size, 1))  # Non utilisÃ© avec triplet loss\n",
        "        \n",
        "        return triplet_batch, dummy_labels\n",
        "\n",
        "print(\"âœ… TripletGeneratorFT dÃ©fini avec optimisations fine-tuning\")\n",
        "print(\"   ğŸ”„ Augmentation conservative\")\n",
        "print(\"   ğŸ¯ Hard negative mining\")\n",
        "print(\"   ğŸ“Š Split train/validation par recette\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ—ï¸ CrÃ©ation du modÃ¨le triplet fine-tuning...\n",
            "âœ… ModÃ¨le triplet crÃ©Ã©:\n",
            "   ğŸ“ Input shape: (None, 3, 224, 224, 3)\n",
            "   ğŸ“ Output shape: (None, 3, 512)\n"
          ]
        }
      ],
      "source": [
        "# ğŸ—ï¸ CRÃ‰ATION DU MODÃˆLE TRIPLET FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "def create_triplet_model_ft(embedding_model):\n",
        "    \"\"\"\n",
        "    ğŸ¯ CrÃ©er le modÃ¨le triplet pour l'entraÃ®nement fine-tuning\n",
        "    \n",
        "    Args:\n",
        "        embedding_model: ModÃ¨le d'embedding prÃ©-crÃ©Ã©\n",
        "    \n",
        "    Returns:\n",
        "        ModÃ¨le triplet compilÃ©\n",
        "    \"\"\"\n",
        "    print(\"ğŸ—ï¸ CrÃ©ation du modÃ¨le triplet fine-tuning...\")\n",
        "    \n",
        "    # Input: batch de triplets (batch_size, 3, height, width, channels)\n",
        "    triplet_input = Input(\n",
        "        shape=(3, CONFIG_FT['IMG_SIZE'], CONFIG_FT['IMG_SIZE'], 3),\n",
        "        name='triplet_input'\n",
        "    )\n",
        "    \n",
        "    # Extraire chaque composante du triplet\n",
        "    anchor_input = ExtractTripletComponent(0, name='extract_anchor')(triplet_input)\n",
        "    positive_input = ExtractTripletComponent(1, name='extract_positive')(triplet_input)\n",
        "    negative_input = ExtractTripletComponent(2, name='extract_negative')(triplet_input)\n",
        "    \n",
        "    # Obtenir les embeddings pour chaque composante\n",
        "    anchor_embedding = embedding_model(anchor_input)\n",
        "    positive_embedding = embedding_model(positive_input)\n",
        "    negative_embedding = embedding_model(negative_input)\n",
        "    \n",
        "    # Empiler les embeddings pour le triplet loss\n",
        "    triplet_output = TripletStackLayer(name='triplet_stack')([\n",
        "        anchor_embedding, \n",
        "        positive_embedding, \n",
        "        negative_embedding\n",
        "    ])\n",
        "    \n",
        "    # CrÃ©er le modÃ¨le triplet\n",
        "    triplet_model = Model(\n",
        "        inputs=triplet_input, \n",
        "        outputs=triplet_output, \n",
        "        name='UltimateTripletModelFT'\n",
        "    )\n",
        "    \n",
        "    print(f\"âœ… ModÃ¨le triplet crÃ©Ã©:\")\n",
        "    print(f\"   ğŸ“ Input shape: {triplet_model.input_shape}\")\n",
        "    print(f\"   ğŸ“ Output shape: {triplet_model.output_shape}\")\n",
        "    \n",
        "    return triplet_model\n",
        "\n",
        "# CrÃ©er le modÃ¨le triplet\n",
        "triplet_model_ft = create_triplet_model_ft(embedding_model_ft)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Fonction d'entraÃ®nement fine-tuning dÃ©finie\n",
            "   ğŸ”¥ Learning rates optimisÃ©s pour fine-tuning\n",
            "   ğŸ“Š Callbacks adaptÃ©s pour stabilitÃ©\n",
            "   ğŸ’¾ Sauvegarde automatique du meilleur modÃ¨le\n"
          ]
        }
      ],
      "source": [
        "# ğŸš€ FONCTION D'ENTRAÃNEMENT FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "def train_fine_tuning():\n",
        "    \"\"\"\n",
        "    ğŸ”¥ EntraÃ®ner le modÃ¨le avec fine-tuning et diffÃ©rents learning rates\n",
        "    \n",
        "    Returns:\n",
        "        embedding_model, history: ModÃ¨le entraÃ®nÃ© et historique\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ DÃ‰MARRAGE DE L'ENTRAÃNEMENT FINE-TUNING\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # CrÃ©er les gÃ©nÃ©rateurs de donnÃ©es (train + validation)\n",
        "    print(\"\\nğŸ“Š CrÃ©ation des gÃ©nÃ©rateurs de donnÃ©es...\")\n",
        "    train_generator = TripletGeneratorFT(\n",
        "        recipes_with_images,\n",
        "        batch_size=CONFIG_FT['BATCH_SIZE'],\n",
        "        img_size=CONFIG_FT['IMG_SIZE'],\n",
        "        augment=CONFIG_FT['USE_AUGMENTATION'],\n",
        "        validation_split=CONFIG_FT['VALIDATION_SPLIT'],\n",
        "        is_validation=False\n",
        "    )\n",
        "    \n",
        "    val_generator = TripletGeneratorFT(\n",
        "        recipes_with_images,\n",
        "        batch_size=CONFIG_FT['BATCH_SIZE'],\n",
        "        img_size=CONFIG_FT['IMG_SIZE'],\n",
        "        augment=False,  # Pas d'augmentation pour validation\n",
        "        validation_split=CONFIG_FT['VALIDATION_SPLIT'],\n",
        "        is_validation=True\n",
        "    )\n",
        "    \n",
        "    # CrÃ©er le modÃ¨le triplet\n",
        "    triplet_model = create_triplet_model_ft(embedding_model_ft)\n",
        "    \n",
        "    # âš¡ COMPILATION AVEC LEARNING RATES DIFFÃ‰RENTIÃ‰S\n",
        "    print(\"\\nâš¡ Compilation du modÃ¨le avec learning rates optimisÃ©s...\")\n",
        "    \n",
        "    # CrÃ©er un optimizer avec learning rate pour fine-tuning\n",
        "    optimizer = Adam(\n",
        "        learning_rate=CONFIG_FT['FINETUNE_LR'],\n",
        "        weight_decay=CONFIG_FT['WEIGHT_DECAY']  # L2 regularization\n",
        "    )\n",
        "    \n",
        "    # Compiler le modÃ¨le\n",
        "    triplet_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=lambda y_true, y_pred: triplet_loss_fn(y_true, y_pred, margin=CONFIG_FT['MARGIN']),\n",
        "        metrics=[triplet_accuracy, average_positive_similarity, average_negative_similarity]\n",
        "    )\n",
        "    \n",
        "    print(f\"   ğŸ“ˆ Optimizer: Adam (lr={CONFIG_FT['FINETUNE_LR']}, wd={CONFIG_FT['WEIGHT_DECAY']})\")\n",
        "    print(f\"   ğŸ¯ Triplet Loss margin: {CONFIG_FT['MARGIN']}\")\n",
        "    print(f\"   ğŸ“Š MÃ©triques: accuracy, pos_sim, neg_sim\")\n",
        "    \n",
        "    # ğŸ“‹ CALLBACKS OPTIMISÃ‰S POUR FINE-TUNING\n",
        "    print(\"\\nğŸ“‹ Configuration des callbacks...\")\n",
        "    \n",
        "    # ModÃ¨le checkpoint pour sauvegarder le meilleur modÃ¨le\n",
        "    checkpoint_path = os.path.join(CONFIG_FT['CHECKPOINT_DIR'], f\"best_{CONFIG_FT['MODEL_NAME']}\")\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        checkpoint_path,\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    )\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=CONFIG_FT['PATIENCE'],\n",
        "        verbose=1,\n",
        "        restore_best_weights=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    \n",
        "    # RÃ©duction du learning rate\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=CONFIG_FT['REDUCE_LR_FACTOR'],\n",
        "        patience=CONFIG_FT['REDUCE_LR_PATIENCE'],\n",
        "        min_lr=CONFIG_FT['MIN_LR'],\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    )\n",
        "    \n",
        "    callbacks = [model_checkpoint, early_stopping, reduce_lr]\n",
        "    \n",
        "    print(f\"   ğŸ’¾ Model checkpoint: {checkpoint_path}\")\n",
        "    print(f\"   â° Early stopping: patience={CONFIG_FT['PATIENCE']}\")\n",
        "    print(f\"   ğŸ“‰ Reduce LR: patience={CONFIG_FT['REDUCE_LR_PATIENCE']}, factor={CONFIG_FT['REDUCE_LR_FACTOR']}\")\n",
        "    print(f\"   ğŸ”» Min LR: {CONFIG_FT['MIN_LR']}\")\n",
        "    \n",
        "    # ğŸ¯ ENTRAÃNEMENT\n",
        "    print(f\"\\nğŸ¯ Lancement de l'entraÃ®nement ({CONFIG_FT['FINETUNE_EPOCHS']} Ã©poques max)...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        history = triplet_model.fit(\n",
        "            train_generator,\n",
        "            epochs=CONFIG_FT['FINETUNE_EPOCHS'],\n",
        "            validation_data=val_generator,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        print(\"\\nâœ… ENTRAÃNEMENT TERMINÃ‰ AVEC SUCCÃˆS!\")\n",
        "        \n",
        "        # Sauvegarder le modÃ¨le d'embedding final\n",
        "        final_model_path = os.path.join(CONFIG_FT['CHECKPOINT_DIR'], CONFIG_FT['MODEL_NAME'])\n",
        "        embedding_model_ft.save(final_model_path)\n",
        "        print(f\"ğŸ’¾ ModÃ¨le d'embedding sauvÃ©: {final_model_path}\")\n",
        "        \n",
        "        # Afficher les rÃ©sultats finaux\n",
        "        print(f\"\\nğŸ“Š RÃ‰SULTATS FINAUX:\")\n",
        "        print(f\"ğŸ“‰ Loss finale: {history.history['val_loss'][-1]:.4f}\")\n",
        "        print(f\"ğŸ“Š PrÃ©cision finale: {history.history['val_triplet_accuracy'][-1]:.4f}\")\n",
        "        print(f\"ğŸ“ˆ SimilaritÃ© pos finale: {history.history['val_average_positive_similarity'][-1]:.4f}\")\n",
        "        print(f\"ğŸ“‰ SimilaritÃ© neg finale: {history.history['val_average_negative_similarity'][-1]:.4f}\")\n",
        "        \n",
        "        return embedding_model_ft, history\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ ERREUR PENDANT L'ENTRAÃNEMENT: {e}\")\n",
        "        return None, None\n",
        "\n",
        "print(\"âœ… Fonction d'entraÃ®nement fine-tuning dÃ©finie\")\n",
        "print(\"   ğŸ”¥ Learning rates optimisÃ©s pour fine-tuning\")\n",
        "print(\"   ğŸ“Š Callbacks adaptÃ©s pour stabilitÃ©\")\n",
        "print(\"   ğŸ’¾ Sauvegarde automatique du meilleur modÃ¨le\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Fonction de visualisation fine-tuning dÃ©finie\n",
            "   ğŸ”§ Graphiques corrigÃ©s (Ã©chelles adaptÃ©es)\n",
            "   ğŸ“Š Analyses automatiques des objectifs\n",
            "   ğŸ¨ Interface dark mode moderne\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“Š VISUALISATION DES RÃ‰SULTATS D'ENTRAÃNEMENT (VERSION CORRIGÃ‰E)\n",
        "# ============================================================================\n",
        "\n",
        "def plot_training_results_ft(history):\n",
        "    \"\"\"Afficher les mÃ©triques d'entraÃ®nement fine-tuning - Version corrigÃ©e\"\"\"\n",
        "    \n",
        "    # Configuration dark mode\n",
        "    plt.style.use('dark_background')\n",
        "    \n",
        "    # Couleurs modernes pour dark mode\n",
        "    colors = {\n",
        "        'primary': '#00D4AA',      # Cyan-vert brillant\n",
        "        'secondary': '#FF6B6B',    # Rouge-coral moderne\n",
        "        'accent': '#4ECDC4',       # Turquoise\n",
        "        'warning': '#FFE66D',      # Jaune moderne\n",
        "        'info': '#A8E6CF',         # Vert pastel\n",
        "        'purple': '#B19CD9'        # Violet pastel\n",
        "    }\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.patch.set_facecolor('#1e1e1e')\n",
        "    fig.suptitle('ğŸ”¥ RÃ©sultats Fine-Tuning (20 couches dÃ©gelÃ©es)', \n",
        "                 fontsize=18, fontweight='bold', color='white', y=0.95)\n",
        "    \n",
        "    # Configuration commune pour tous les axes\n",
        "    for ax in axes.flat:\n",
        "        ax.set_facecolor('#2d2d2d')\n",
        "        ax.tick_params(colors='white', which='both')\n",
        "        ax.xaxis.label.set_color('white')\n",
        "        ax.yaxis.label.set_color('white')\n",
        "        ax.title.set_color('white')\n",
        "        ax.grid(True, alpha=0.2, color='gray', linestyle='-', linewidth=0.5)\n",
        "        ax.spines['bottom'].set_color('white')\n",
        "        ax.spines['top'].set_color('white')\n",
        "        ax.spines['right'].set_color('white')\n",
        "        ax.spines['left'].set_color('white')\n",
        "    \n",
        "    # Loss (inchangÃ©)\n",
        "    axes[0, 0].plot(history.history['loss'], label='ğŸ“ˆ Train Loss', \n",
        "                    linewidth=3, color=colors['primary'], alpha=0.9)\n",
        "    axes[0, 0].plot(history.history['val_loss'], label='ğŸ“‰ Val Loss', \n",
        "                    linewidth=3, color=colors['secondary'], alpha=0.9)\n",
        "    axes[0, 0].fill_between(range(len(history.history['loss'])), \n",
        "                           history.history['loss'], alpha=0.1, color=colors['primary'])\n",
        "    axes[0, 0].fill_between(range(len(history.history['val_loss'])), \n",
        "                           history.history['val_loss'], alpha=0.1, color=colors['secondary'])\n",
        "    axes[0, 0].set_title('ğŸ¯ Triplet Loss Evolution', fontweight='bold', fontsize=14)\n",
        "    axes[0, 0].set_xlabel('Ã‰poque', fontweight='bold')\n",
        "    axes[0, 0].set_ylabel('Loss Value', fontweight='bold')\n",
        "    axes[0, 0].legend(frameon=True, fancybox=True, shadow=True, \n",
        "                     facecolor='#3d3d3d', edgecolor='white')\n",
        "    \n",
        "    # âœ… CORRECTION: Accuracy avec Ã©chelle adaptÃ©e\n",
        "    axes[0, 1].plot(history.history['triplet_accuracy'], label='ğŸ“Š Train Accuracy', \n",
        "                    linewidth=3, color=colors['accent'], alpha=0.9, marker='o', markersize=4)\n",
        "    axes[0, 1].plot(history.history['val_triplet_accuracy'], label='ğŸ“‹ Val Accuracy', \n",
        "                    linewidth=3, color=colors['warning'], alpha=0.9, marker='s', markersize=4)\n",
        "    axes[0, 1].fill_between(range(len(history.history['triplet_accuracy'])), \n",
        "                           history.history['triplet_accuracy'], alpha=0.1, color=colors['accent'])\n",
        "    axes[0, 1].fill_between(range(len(history.history['val_triplet_accuracy'])), \n",
        "                           history.history['val_triplet_accuracy'], alpha=0.1, color=colors['warning'])\n",
        "    \n",
        "    # âœ… CORRECTION: Ligne de rÃ©fÃ©rence plus haute + Ã©chelle adaptÃ©e\n",
        "    axes[0, 1].axhline(y=0.95, color='white', linestyle='--', alpha=0.5, label='Target (95%)')\n",
        "    \n",
        "    # âœ… CORRECTION: Ã‰chelle Y adaptÃ©e pour mieux voir les variations\n",
        "    min_acc = min(min(history.history['triplet_accuracy']), min(history.history['val_triplet_accuracy']))\n",
        "    axes[0, 1].set_ylim(max(0.8, min_acc - 0.05), 1.02)  # Focus sur la zone utile\n",
        "    \n",
        "    axes[0, 1].set_title('ğŸ“Š Triplet Accuracy Progress', fontweight='bold', fontsize=14)\n",
        "    axes[0, 1].set_xlabel('Ã‰poque', fontweight='bold')\n",
        "    axes[0, 1].set_ylabel('Accuracy Score', fontweight='bold')\n",
        "    axes[0, 1].legend(frameon=True, fancybox=True, shadow=True, \n",
        "                     facecolor='#3d3d3d', edgecolor='white')\n",
        "    \n",
        "    # âœ… CORRECTION: Positive Similarity avec zone cible rÃ©aliste\n",
        "    axes[1, 0].plot(history.history['average_positive_similarity'], label='ğŸ”— Train Pos Sim', \n",
        "                    linewidth=3, color=colors['info'], alpha=0.9, marker='o', markersize=4)\n",
        "    axes[1, 0].plot(history.history['val_average_positive_similarity'], label='âœ… Val Pos Sim', \n",
        "                    linewidth=3, color=colors['purple'], alpha=0.9, marker='s', markersize=4)\n",
        "    axes[1, 0].fill_between(range(len(history.history['average_positive_similarity'])), \n",
        "                           history.history['average_positive_similarity'], alpha=0.1, color=colors['info'])\n",
        "    axes[1, 0].fill_between(range(len(history.history['val_average_positive_similarity'])), \n",
        "                           history.history['val_average_positive_similarity'], alpha=0.1, color=colors['purple'])\n",
        "    \n",
        "    # âœ… CORRECTION: Zone d'objectif rÃ©aliste pour similarity positive (0.5-0.8)\n",
        "    axes[1, 0].axhspan(0.5, 0.8, alpha=0.1, color='green', label='Good Zone (0.5-0.8)')\n",
        "    axes[1, 0].axhline(y=0.6, color='lime', linestyle='--', alpha=0.7, label='Target (0.6+)')\n",
        "    \n",
        "    axes[1, 0].set_title('ğŸ“ˆ Positive Similarity (Anchor-Positive)', fontweight='bold', fontsize=14)\n",
        "    axes[1, 0].set_xlabel('Ã‰poque', fontweight='bold')\n",
        "    axes[1, 0].set_ylabel('Cosine Similarity', fontweight='bold')\n",
        "    axes[1, 0].legend(frameon=True, fancybox=True, shadow=True, \n",
        "                     facecolor='#3d3d3d', edgecolor='white')\n",
        "    axes[1, 0].set_ylim(-0.2, 1.0)  # Zoom sur la zone utile\n",
        "    \n",
        "    # Negative Similarity (inchangÃ© mais amÃ©liorÃ©)\n",
        "    axes[1, 1].plot(history.history['average_negative_similarity'], label='âŒ Train Neg Sim', \n",
        "                    linewidth=3, color=colors['secondary'], alpha=0.9, marker='o', markersize=4)\n",
        "    axes[1, 1].plot(history.history['val_average_negative_similarity'], label='ğŸš« Val Neg Sim', \n",
        "                    linewidth=3, color=colors['primary'], alpha=0.9, marker='s', markersize=4)\n",
        "    axes[1, 1].fill_between(range(len(history.history['average_negative_similarity'])), \n",
        "                           history.history['average_negative_similarity'], alpha=0.1, color=colors['secondary'])\n",
        "    axes[1, 1].fill_between(range(len(history.history['val_average_negative_similarity'])), \n",
        "                           history.history['val_average_negative_similarity'], alpha=0.1, color=colors['primary'])\n",
        "    \n",
        "    # Zone d'objectif pour similarity nÃ©gative (<0.3)\n",
        "    axes[1, 1].axhspan(-1.0, 0.3, alpha=0.1, color='red', label='Target Zone (<0.3)')\n",
        "    axes[1, 1].axhline(y=0.2, color='orange', linestyle='--', alpha=0.7, label='Good (<0.2)')\n",
        "    \n",
        "    axes[1, 1].set_title('ğŸ“‰ Negative Similarity (Anchor-Negative)', fontweight='bold', fontsize=14)\n",
        "    axes[1, 1].set_xlabel('Ã‰poque', fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('Cosine Similarity', fontweight='bold')\n",
        "    axes[1, 1].legend(frameon=True, fancybox=True, shadow=True, \n",
        "                     facecolor='#3d3d3d', edgecolor='white')\n",
        "    axes[1, 1].set_ylim(-0.2, 0.8)  # Focus sur la zone utile\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.92)\n",
        "    plt.show()\n",
        "    \n",
        "    # âœ… BONUS: Affichage des statistiques finales\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ“Š RÃ‰SULTATS FINAUX FINE-TUNING:\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"ğŸ¯ Loss finale (val): {history.history['val_loss'][-1]:.4f}\")\n",
        "    print(f\"ğŸ“Š Accuracy finale (val): {history.history['val_triplet_accuracy'][-1]:.4f}\")\n",
        "    print(f\"ğŸ“ˆ Pos Similarity finale (val): {history.history['val_average_positive_similarity'][-1]:.4f}\")\n",
        "    print(f\"ğŸ“‰ Neg Similarity finale (val): {history.history['val_average_negative_similarity'][-1]:.4f}\")\n",
        "    gap = history.history['val_average_positive_similarity'][-1] - history.history['val_average_negative_similarity'][-1]\n",
        "    print(f\"ğŸ“ Ã‰cart Pos-Neg: {gap:.4f}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Comparaison avec les targets\n",
        "    final_accuracy = history.history['val_triplet_accuracy'][-1]\n",
        "    final_pos_sim = history.history['val_average_positive_similarity'][-1]\n",
        "    final_neg_sim = history.history['val_average_negative_similarity'][-1]\n",
        "    \n",
        "    print(f\"\\nğŸ¯ ANALYSE DES OBJECTIFS:\")\n",
        "    print(f\"   ğŸ“Š Accuracy: {'âœ…' if final_accuracy > 0.95 else 'âš ï¸'} {final_accuracy:.3f} (target: >0.95)\")\n",
        "    print(f\"   ğŸ“ˆ Pos Sim: {'âœ…' if final_pos_sim > 0.6 else 'âš ï¸'} {final_pos_sim:.3f} (target: >0.6)\")\n",
        "    print(f\"   ğŸ“‰ Neg Sim: {'âœ…' if final_neg_sim < 0.3 else 'âš ï¸'} {final_neg_sim:.3f} (target: <0.3)\")\n",
        "    print(f\"   ğŸ“ Gap: {'âœ…' if gap > 0.3 else 'âš ï¸'} {gap:.3f} (target: >0.3)\")\n",
        "    \n",
        "    # Reset style\n",
        "    plt.style.use('default')\n",
        "\n",
        "print(\"âœ… Fonction de visualisation fine-tuning dÃ©finie\")\n",
        "print(\"   ğŸ”§ Graphiques corrigÃ©s (Ã©chelles adaptÃ©es)\")\n",
        "print(\"   ğŸ“Š Analyses automatiques des objectifs\")\n",
        "print(\"   ğŸ¨ Interface dark mode moderne\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RecipeImageRetrievalFT dÃ©finie\n",
            "   ğŸ§  Calcul d'embeddings optimisÃ©\n",
            "   ğŸ“Š Base de donnÃ©es automatique\n",
            "   ğŸ” Recherche par similaritÃ©\n",
            "   ğŸ¨ Visualisation des rÃ©sultats\n"
          ]
        }
      ],
      "source": [
        "# ğŸš€ CLASSE COMPLÃˆTE RECIPE IMAGE RETRIEVAL FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "class RecipeImageRetrievalFT:\n",
        "    \"\"\"\n",
        "    ğŸ”¥ SystÃ¨me de rÃ©cupÃ©ration d'images de recettes avec modÃ¨le fine-tunÃ©\n",
        "    Version optimisÃ©e pour performance et prÃ©cision maximale\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path=None, recipes_df=None):\n",
        "        \"\"\"Initialiser le systÃ¨me de rÃ©cupÃ©ration fine-tuning\"\"\"\n",
        "        print(\"ğŸš€ Initialisation RecipeImageRetrievalFT...\")\n",
        "        \n",
        "        # Configuration\n",
        "        self.img_size = CONFIG_FT['IMG_SIZE']\n",
        "        self.embedding_dim = CONFIG_FT['EMBEDDING_DIM']\n",
        "        self.model_name = CONFIG_FT['MODEL_NAME']\n",
        "        \n",
        "        # Charger le modÃ¨le\n",
        "        if model_path and os.path.exists(model_path):\n",
        "            print(f\"ğŸ“¦ Chargement du modÃ¨le depuis: {model_path}\")\n",
        "            self.model = load_model(model_path, compile=False)\n",
        "        else:\n",
        "            print(\"âŒ Aucun modÃ¨le trouvÃ©!\")\n",
        "            self.model = None\n",
        "            return\n",
        "        \n",
        "        # Base de donnÃ©es des recettes\n",
        "        self.recipes_df = recipes_df\n",
        "        self.embeddings_db = None\n",
        "        \n",
        "        # Cache pour les performances\n",
        "        self.embedding_cache = {}\n",
        "        \n",
        "        print(f\"âœ… RecipeImageRetrievalFT initialisÃ© avec:\")\n",
        "        print(f\"   ğŸ—ï¸ ModÃ¨le: {self.model_name}\")\n",
        "        print(f\"   ğŸ“ Taille image: {self.img_size}x{self.img_size}\")\n",
        "        print(f\"   ğŸ§  Dimension embedding: {self.embedding_dim}\")\n",
        "        print(f\"   ğŸ“Š Recettes: {len(self.recipes_df) if self.recipes_df is not None else 0}\")\n",
        "    \n",
        "    def compute_embedding(self, image_path_or_array):\n",
        "        \"\"\"Calculer l'embedding d'une image\"\"\"\n",
        "        try:\n",
        "            # Cache check\n",
        "            if isinstance(image_path_or_array, str) and image_path_or_array in self.embedding_cache:\n",
        "                return self.embedding_cache[image_path_or_array]\n",
        "            \n",
        "            # Preprocessing\n",
        "            if isinstance(image_path_or_array, str):\n",
        "                img = preprocess_image(image_path_or_array, self.img_size)\n",
        "            else:\n",
        "                img = image_path_or_array\n",
        "            \n",
        "            # Ajouter dimension batch si nÃ©cessaire\n",
        "            if len(img.shape) == 3:\n",
        "                img = np.expand_dims(img, axis=0)\n",
        "            \n",
        "            # Calculer embedding\n",
        "            embedding = self.model.predict(img, verbose=0)[0]\n",
        "            \"\"\"\n",
        "            DOUBLE EMBEDDING ??\n",
        "            \"\"\"\n",
        "            # embedding = embedding / np.linalg.norm(embedding)  # Normalisation L2\n",
        "            \n",
        "            # Cache si c'est un path\n",
        "            if isinstance(image_path_or_array, str):\n",
        "                self.embedding_cache[image_path_or_array] = embedding\n",
        "            \n",
        "            return embedding\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Erreur lors du calcul d'embedding: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def build_database(self, force_rebuild=False):\n",
        "        \"\"\"Construire la base de donnÃ©es d'embeddings\"\"\"\n",
        "        db_path = f\"ft/{self.model_name.replace('.keras', '')}_embeddings_database_ft.npy\"\n",
        "        \n",
        "        if os.path.exists(db_path) and not force_rebuild:\n",
        "            print(f\"ğŸ“¦ Chargement de la base de donnÃ©es: {db_path}\")\n",
        "            self.embeddings_db = np.load(db_path)\n",
        "            print(f\"âœ… Base chargÃ©e: {self.embeddings_db.shape}\")\n",
        "            return\n",
        "        \n",
        "        if self.recipes_df is None:\n",
        "            print(\"âŒ Aucune donnÃ©e de recettes disponible!\")\n",
        "            return\n",
        "        \n",
        "        print(f\"ğŸ”¨ Construction de la base d'embeddings...\")\n",
        "        print(f\"   ğŸ“Š Nombre de recettes: {len(self.recipes_df)}\")\n",
        "        \n",
        "        embeddings = []\n",
        "        valid_indices = []\n",
        "        \n",
        "        for idx, row in tqdm(self.recipes_df.iterrows(), \n",
        "                            total=len(self.recipes_df), \n",
        "                            desc=\"ğŸ§  Embeddings\"):\n",
        "            if pd.notna(row.get('image_path')) and os.path.exists(row['image_path']):\n",
        "                embedding = self.compute_embedding(row['image_path'])\n",
        "                if embedding is not None:\n",
        "                    embeddings.append(embedding)\n",
        "                    valid_indices.append(idx)\n",
        "        \n",
        "        if embeddings:\n",
        "            self.embeddings_db = np.array(embeddings)\n",
        "            \n",
        "            # Sauvegarder\n",
        "            os.makedirs('ft', exist_ok=True)\n",
        "            np.save(db_path, self.embeddings_db)\n",
        "            \n",
        "            # Filtrer le DataFrame pour garder seulement les recettes valides\n",
        "            self.recipes_df = self.recipes_df.loc[valid_indices].reset_index(drop=True)\n",
        "            \n",
        "            print(f\"âœ… Base construite et sauvÃ©e:\")\n",
        "            print(f\"   ğŸ“Š Embeddings: {self.embeddings_db.shape}\")\n",
        "            print(f\"   ğŸ’¾ SauvÃ© dans: {db_path}\")\n",
        "            print(f\"   ğŸ“‹ Recettes valides: {len(self.recipes_df)}\")\n",
        "        else:\n",
        "            print(\"âŒ Aucun embedding valide crÃ©Ã©!\")\n",
        "    \n",
        "    def search_similar_recipes(self, query_image_path, top_k=5, min_similarity=0.3):\n",
        "        \"\"\"Rechercher les recettes similaires Ã  une image\"\"\"\n",
        "        if self.embeddings_db is None:\n",
        "            print(\"âŒ Base de donnÃ©es non construite! Appelez build_database() d'abord.\")\n",
        "            return []\n",
        "        \n",
        "        # Calculer embedding de la requÃªte\n",
        "        query_embedding = self.compute_embedding(query_image_path)\n",
        "        if query_embedding is None:\n",
        "            print(\"âŒ Impossible de calculer l'embedding de l'image requÃªte\")\n",
        "            return []\n",
        "        \n",
        "        # Calculer similaritÃ©s\n",
        "        similarities = np.dot(self.embeddings_db, query_embedding)\n",
        "        \n",
        "        # Trouver les top_k\n",
        "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "        top_similarities = similarities[top_indices]\n",
        "        \n",
        "        # Filtrer par similaritÃ© minimale\n",
        "        results = []\n",
        "        for idx, sim in zip(top_indices, top_similarities):\n",
        "            if sim >= min_similarity:\n",
        "                recipe = self.recipes_df.iloc[idx]\n",
        "                results.append({\n",
        "                    'recipe_title': recipe['Title'],\n",
        "                    'similarity': float(sim),\n",
        "                    'image_path': recipe['image_path'],\n",
        "                    'index': int(idx)\n",
        "                })\n",
        "        \n",
        "        return results\n",
        "\n",
        "print(\"âœ… RecipeImageRetrievalFT dÃ©finie\")\n",
        "print(\"   ğŸ§  Calcul d'embeddings optimisÃ©\")\n",
        "print(\"   ğŸ“Š Base de donnÃ©es automatique\")\n",
        "print(\"   ğŸ” Recherche par similaritÃ©\")\n",
        "print(\"   ğŸ¨ Visualisation des rÃ©sultats\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ DÃ‰MARRAGE DE L'ENTRAÃNEMENT FINE-TUNING COMPLET\n",
            "============================================================\n",
            "ğŸš€ DÃ‰MARRAGE DE L'ENTRAÃNEMENT FINE-TUNING\n",
            "============================================================\n",
            "\n",
            "ğŸ“Š CrÃ©ation des gÃ©nÃ©rateurs de donnÃ©es...\n",
            "ğŸ” Filtrage des recettes avec images valides...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13463/13463 [00:15<00:00, 851.22it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… 13463/13463 images valides\n",
            "ğŸ“Š Split: 10774 train, 2689 validation\n",
            "ğŸ”„ TripletGeneratorFT (Training):\n",
            "   ğŸ“Š Total recettes: 10774\n",
            "   ğŸ“¸ Images: 10774\n",
            "   ğŸ”„ Augmentation: ON (conservative)\n",
            "ğŸ” Filtrage des recettes avec images valides...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13463/13463 [00:06<00:00, 1972.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… 13463/13463 images valides\n",
            "ğŸ“Š Split: 10774 train, 2689 validation\n",
            "ğŸ”„ TripletGeneratorFT (Validation):\n",
            "   ğŸ“Š Total recettes: 2689\n",
            "   ğŸ“¸ Images: 2689\n",
            "   ğŸ”„ Augmentation: OFF\n",
            "ğŸ—ï¸ CrÃ©ation du modÃ¨le triplet fine-tuning...\n",
            "âœ… ModÃ¨le triplet crÃ©Ã©:\n",
            "   ğŸ“ Input shape: (None, 3, 224, 224, 3)\n",
            "   ğŸ“ Output shape: (None, 3, 512)\n",
            "\n",
            "âš¡ Compilation du modÃ¨le avec learning rates optimisÃ©s...\n",
            "   ğŸ“ˆ Optimizer: Adam (lr=5e-05, wd=0.0001)\n",
            "   ğŸ¯ Triplet Loss margin: 0.2\n",
            "   ğŸ“Š MÃ©triques: accuracy, pos_sim, neg_sim\n",
            "\n",
            "ğŸ“‹ Configuration des callbacks...\n",
            "   ğŸ’¾ Model checkpoint: ./ft/best_recipe_image_retrieval_model_ft.keras\n",
            "   â° Early stopping: patience=5\n",
            "   ğŸ“‰ Reduce LR: patience=3, factor=0.5\n",
            "   ğŸ”» Min LR: 1e-07\n",
            "\n",
            "ğŸ¯ Lancement de l'entraÃ®nement (25 Ã©poques max)...\n",
            "============================================================\n",
            "Epoch 1/25\n",
            "\u001b[1m168/673\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m20:57\u001b[0m 2s/step - average_negative_similarity: 5.1980e-04 - average_positive_similarity: 0.2415 - loss: 0.0272 - triplet_accuracy: 0.9753"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Lancer l'entraÃ®nement\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m trained_model_ft, history_ft = \u001b[43mtrain_fine_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trained_model_ft \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m history_ft \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ‰ ENTRAÃNEMENT TERMINÃ‰ AVEC SUCCÃˆS!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 102\u001b[39m, in \u001b[36mtrain_fine_tuning\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     history = \u001b[43mtriplet_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG_FT\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFINETUNE_EPOCHS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ… ENTRAÃNEMENT TERMINÃ‰ AVEC SUCCÃˆS!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# Sauvegarder le modÃ¨le d'embedding final\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\DEV\\itadaki\\itadaki_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ğŸ¯ ENTRAÃNEMENT DU MODÃˆLE FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸš€ DÃ‰MARRAGE DE L'ENTRAÃNEMENT FINE-TUNING COMPLET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Lancer l'entraÃ®nement\n",
        "trained_model_ft, history_ft = train_fine_tuning()\n",
        "\n",
        "if trained_model_ft is not None and history_ft is not None:\n",
        "    print(\"\\nğŸ‰ ENTRAÃNEMENT TERMINÃ‰ AVEC SUCCÃˆS!\")\n",
        "    \n",
        "    # Visualiser les rÃ©sultats\n",
        "    print(\"\\nğŸ“Š Visualisation des rÃ©sultats d'entraÃ®nement...\")\n",
        "    plot_training_results_ft(history_ft)\n",
        "    \n",
        "    print(\"\\nâœ… Fine-tuning completed successfully!\")\n",
        "    print(f\"   ğŸ“ ModÃ¨le sauvÃ© dans: ft/{CONFIG_FT['MODEL_NAME']}\")\n",
        "    print(f\"   ğŸ“Š Base de donnÃ©es d'embeddings prÃªte\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ ERREUR PENDANT L'ENTRAÃNEMENT!\")\n",
        "    print(\"   VÃ©rifiez les logs ci-dessus pour les dÃ©tails\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”§ INITIALISATION DU SYSTÃˆME DE RÃ‰CUPÃ‰RATION FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ”§ Initialisation du systÃ¨me de rÃ©cupÃ©ration fine-tuning...\")\n",
        "\n",
        "# Charger le modÃ¨le entraÃ®nÃ©\n",
        "model_path_ft = f\"ft/{CONFIG_FT['MODEL_NAME']}\"\n",
        "\n",
        "if os.path.exists(model_path_ft):\n",
        "    # CrÃ©er le systÃ¨me de rÃ©cupÃ©ration\n",
        "    retrieval_system_ft = RecipeImageRetrievalFT(\n",
        "        model_path=model_path_ft,\n",
        "        recipes_df=recipes_with_images.copy()\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nğŸ”¨ Construction de la base de donnÃ©es d'embeddings...\")\n",
        "    retrieval_system_ft.build_database(force_rebuild=False)\n",
        "    \n",
        "    print(f\"\\nâœ… SYSTÃˆME DE RÃ‰CUPÃ‰RATION FINE-TUNING PRÃŠT!\")\n",
        "    print(f\"   ğŸ—ï¸ ModÃ¨le: {model_path_ft}\")\n",
        "    print(f\"   ğŸ“Š Base d'embeddings: {retrieval_system_ft.embeddings_db.shape if retrieval_system_ft.embeddings_db is not None else 'Non crÃ©Ã©e'}\")\n",
        "    print(f\"   ğŸ“‹ Recettes dans la base: {len(retrieval_system_ft.recipes_df) if retrieval_system_ft.recipes_df is not None else 0}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"âŒ ModÃ¨le non trouvÃ©: {model_path_ft}\")\n",
        "    print(\"   Vous devez d'abord entraÃ®ner le modÃ¨le!\")\n",
        "    retrieval_system_ft = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ² TEST AVEC IMAGES ALÃ‰ATOIRES - FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "if retrieval_system_ft is not None:\n",
        "    print(\"ğŸ² Test avec des images alÃ©atoires du dataset...\")\n",
        "    \n",
        "    # SÃ©lectionner quelques recettes alÃ©atoires pour les tests\n",
        "    test_recipes = retrieval_system_ft.recipes_df.sample(n=3, random_state=42)\n",
        "    \n",
        "    for i, (_, recipe) in enumerate(test_recipes.iterrows()):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸ§ª TEST {i+1}/3: {recipe['Title']}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        try:\n",
        "            # Recherche\n",
        "            results = retrieval_system_ft.search_similar_recipes(\n",
        "                query_image_path=recipe['image_path'],\n",
        "                top_k=5,\n",
        "                min_similarity=0.3\n",
        "            )\n",
        "            \n",
        "            if results:\n",
        "                print(f\"âœ… {len(results)} rÃ©sultats trouvÃ©s!\")\n",
        "                \n",
        "                # Afficher les rÃ©sultats\n",
        "                print(f\"\\nğŸ“Š TOP RÃ‰SULTATS:\")\n",
        "                for j, result in enumerate(results[:3]):\n",
        "                    print(f\"  #{j+1}. {result['recipe_title'][:50]}...\")\n",
        "                    print(f\"      ğŸ“Š SimilaritÃ©: {result['similarity']:.4f}\")\n",
        "                \n",
        "                # VÃ©rifier si la mÃªme recette est en premiÃ¨re position\n",
        "                if len(results) > 0 and results[0]['recipe_title'] == recipe['Title']:\n",
        "                    print(f\"ğŸ¯ PARFAIT! MÃªme recette trouvÃ©e en premier (sim: {results[0]['similarity']:.4f})\")\n",
        "                else:\n",
        "                    print(f\"âš ï¸ Recette diffÃ©rente en premier: {results[0]['recipe_title'][:40]}\")\n",
        "                \n",
        "            else:\n",
        "                print(\"âŒ Aucun rÃ©sultat trouvÃ© (similaritÃ© trop faible)\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Erreur lors du test: {e}\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"âœ… TESTS AVEC IMAGES ALÃ‰ATOIRES TERMINÃ‰S\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ SystÃ¨me de rÃ©cupÃ©ration non initialisÃ©!\")\n",
        "    print(\"   Initialisez d'abord le systÃ¨me avec un modÃ¨le entraÃ®nÃ©.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ–¼ï¸ TEST AVEC IMAGES CUSTOM - FINE-TUNING\n",
        "# ============================================================================\n",
        "\n",
        "if retrieval_system_ft is not None:\n",
        "    print(\"ğŸ–¼ï¸ Test avec des images custom du dossier test_recipes...\")\n",
        "    \n",
        "    # Dossier des images de test\n",
        "    test_images_dir = \"test_recipes\"\n",
        "    \n",
        "    if os.path.exists(test_images_dir):\n",
        "        # Lister toutes les images de test\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
        "        test_images = []\n",
        "        \n",
        "        for ext in image_extensions:\n",
        "            test_images.extend(glob.glob(os.path.join(test_images_dir, f\"*{ext}\")))\n",
        "            test_images.extend(glob.glob(os.path.join(test_images_dir, f\"*{ext.upper()}\")))\n",
        "        \n",
        "        if test_images:\n",
        "            print(f\"ğŸ“ {len(test_images)} images trouvÃ©es dans {test_images_dir}\")\n",
        "            \n",
        "            # Tester les 3 premiÃ¨res images (ou toutes si moins de 3)\n",
        "            images_to_test = test_images[:min(3, len(test_images))]\n",
        "            \n",
        "            for i, test_image_path in enumerate(images_to_test):\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"ğŸ§ª TEST CUSTOM {i+1}/{len(images_to_test)}: {os.path.basename(test_image_path)}\")\n",
        "                print(f\"{'='*60}\")\n",
        "                \n",
        "                try:\n",
        "                    # Recherche\n",
        "                    results = retrieval_system_ft.search_similar_recipes(\n",
        "                        query_image_path=test_image_path,\n",
        "                        top_k=5,\n",
        "                        min_similarity=0.2  # Seuil plus bas pour images externes\n",
        "                    )\n",
        "                    \n",
        "                    if results:\n",
        "                        print(f\"âœ… {len(results)} rÃ©sultats trouvÃ©s!\")\n",
        "                        \n",
        "                        # Afficher les dÃ©tails\n",
        "                        print(f\"\\nğŸ“Š RÃ‰SULTATS DÃ‰TAILLÃ‰S:\")\n",
        "                        for j, result in enumerate(results):\n",
        "                            print(f\"  #{j+1}. {result['recipe_title']}\")\n",
        "                            print(f\"      ğŸ“Š SimilaritÃ©: {result['similarity']:.4f}\")\n",
        "                            print(f\"      ğŸ“ Path: {result['image_path']}\")\n",
        "                            print()\n",
        "                        \n",
        "                        # Ã‰valuation qualitative\n",
        "                        best_sim = results[0]['similarity']\n",
        "                        if best_sim >= 0.7:\n",
        "                            print(f\"ğŸŒŸ EXCELLENTE correspondance! (sim: {best_sim:.4f})\")\n",
        "                        elif best_sim >= 0.5:\n",
        "                            print(f\"ğŸ‘ BONNE correspondance (sim: {best_sim:.4f})\")\n",
        "                        elif best_sim >= 0.3:\n",
        "                            print(f\"âš ï¸ Correspondance MOYENNE (sim: {best_sim:.4f})\")\n",
        "                        else:\n",
        "                            print(f\"âŒ Correspondance FAIBLE (sim: {best_sim:.4f})\")\n",
        "                        \n",
        "                    else:\n",
        "                        print(\"âŒ Aucun rÃ©sultat trouvÃ© (similaritÃ© trop faible)\")\n",
        "                        print(\"   Essayez de rÃ©duire min_similarity ou vÃ©rifiez l'image\")\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ Erreur lors du test: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "            \n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"âœ… TESTS AVEC IMAGES CUSTOM TERMINÃ‰S\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "        else:\n",
        "            print(f\"âŒ Aucune image trouvÃ©e dans {test_images_dir}\")\n",
        "            print(f\"   Extensions supportÃ©es: {image_extensions}\")\n",
        "    else:\n",
        "        print(f\"âŒ Dossier {test_images_dir} non trouvÃ©!\")\n",
        "        print(\"   CrÃ©ez le dossier et ajoutez-y des images de recettes pour les tests\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ SystÃ¨me de rÃ©cupÃ©ration non initialisÃ©!\")\n",
        "    print(\"   Initialisez d'abord le systÃ¨me avec un modÃ¨le entraÃ®nÃ©.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ‰ RÃ‰SUMÃ‰ FINAL - FINE-TUNING COMPLET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ‰ RÃ‰SUMÃ‰ FINAL DU NOTEBOOK FINE-TUNING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nğŸ”¥ CONFIGURATION FINE-TUNING:\")\n",
        "print(f\"   ğŸ“ Taille image: {CONFIG_FT['IMG_SIZE']}x{CONFIG_FT['IMG_SIZE']}\")\n",
        "print(f\"   ğŸ§  Dimension embedding: {CONFIG_FT['EMBEDDING_DIM']}\")\n",
        "print(f\"   ğŸ“š Batch size: {CONFIG_FT['BATCH_SIZE']}\")\n",
        "print(f\"   ğŸ“ˆ Learning rate: {CONFIG_FT['FINETUNE_LR']}\")\n",
        "print(f\"   ğŸ¯ Marge triplet: {CONFIG_FT['MARGIN']}\")\n",
        "print(f\"   â„ï¸ Couches gelÃ©es: {CONFIG_FT['FREEZE_LAYERS']}\")\n",
        "print(f\"   ğŸ”¥ Couches dÃ©gelÃ©es: 20 derniÃ¨res couches\")\n",
        "\n",
        "print(f\"\\nğŸ—ï¸ ARCHITECTURE:\")\n",
        "print(f\"   ğŸ–¼ï¸ Base: EfficientNetB0 prÃ©-entraÃ®nÃ©\")\n",
        "print(f\"   ğŸ§  Embedding: Couche dense {CONFIG_FT['EMBEDDING_DIM']}D + L2 norm\")\n",
        "print(f\"   ğŸ¯ Loss: Triplet Loss avec hard negative mining\")\n",
        "print(f\"   ğŸ“Š Augmentation: Conservative pour fine-tuning\")\n",
        "\n",
        "print(f\"\\nğŸ“Š DONNÃ‰ES:\")\n",
        "if 'recipes_with_images' in globals():\n",
        "    print(f\"   ğŸ“‹ Recettes totales: {len(recipes_with_images)}\")\n",
        "    print(f\"   ğŸ“¸ Images disponibles: {len(recipes_with_images)}\")\n",
        "    print(f\"   ğŸ”„ Split: {int((1-CONFIG_FT['VALIDATION_SPLIT'])*100)}% train / {int(CONFIG_FT['VALIDATION_SPLIT']*100)}% validation\")\n",
        "else:\n",
        "    print(\"   âŒ DonnÃ©es non chargÃ©es\")\n",
        "\n",
        "print(f\"\\nğŸ¤– MODÃˆLE:\")\n",
        "model_path_ft = f\"ft/{CONFIG_FT['MODEL_NAME']}\"\n",
        "if os.path.exists(model_path_ft):\n",
        "    print(f\"   âœ… ModÃ¨le entraÃ®nÃ©: {model_path_ft}\")\n",
        "    print(f\"   ğŸ’¾ Taille: {os.path.getsize(model_path_ft) / (1024*1024):.1f} MB\")\n",
        "else:\n",
        "    print(f\"   âŒ ModÃ¨le non trouvÃ©: {model_path_ft}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š SYSTÃˆME DE RÃ‰CUPÃ‰RATION:\")\n",
        "if 'retrieval_system_ft' in globals() and retrieval_system_ft is not None:\n",
        "    print(f\"   âœ… SystÃ¨me initialisÃ©\")\n",
        "    if retrieval_system_ft.embeddings_db is not None:\n",
        "        print(f\"   ğŸ“Š Base d'embeddings: {retrieval_system_ft.embeddings_db.shape}\")\n",
        "        print(f\"   ğŸ“‹ Recettes indexÃ©es: {len(retrieval_system_ft.recipes_df)}\")\n",
        "    else:\n",
        "        print(f\"   âš ï¸ Base d'embeddings non construite\")\n",
        "else:\n",
        "    print(f\"   âŒ SystÃ¨me non initialisÃ©\")\n",
        "\n",
        "print(f\"\\nğŸ“ˆ PERFORMANCE ATTENDUE:\")\n",
        "print(f\"   ğŸ¯ Objectif Accuracy: >95%\")\n",
        "print(f\"   ğŸ“ˆ Objectif Pos Similarity: >0.6\")\n",
        "print(f\"   ğŸ“‰ Objectif Neg Similarity: <0.3\")\n",
        "print(f\"   ğŸ“ Objectif Gap Pos-Neg: >0.3\")\n",
        "\n",
        "print(f\"\\nğŸ§ª TESTS DISPONIBLES:\")\n",
        "print(f\"   ğŸ² Images alÃ©atoires du dataset\")\n",
        "print(f\"   ğŸ–¼ï¸ Images custom du dossier test_recipes/\")\n",
        "print(f\"   ğŸ“Š Visualisation des rÃ©sultats\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ UTILISATION:\")\n",
        "print(f\"   1ï¸âƒ£ EntraÃ®ner: train_fine_tuning()\")\n",
        "print(f\"   2ï¸âƒ£ Initialiser: RecipeImageRetrievalFT()\")\n",
        "print(f\"   3ï¸âƒ£ Rechercher: search_similar_recipes()\")\n",
        "print(f\"   4ï¸âƒ£ Visualiser: plot_training_results_ft()\")\n",
        "\n",
        "print(f\"\\nğŸ”„ AMÃ‰LIORATIONS PAR RAPPORT AU TRANSFER LEARNING:\")\n",
        "print(f\"   ğŸ”¥ Fine-tuning des 20 derniÃ¨res couches\")\n",
        "print(f\"   ğŸ“ˆ Learning rate adaptÃ© (1e-5)\")\n",
        "print(f\"   ğŸ›¡ï¸ Augmentation conservative\")\n",
        "print(f\"   âš–ï¸ Weight decay pour rÃ©gularisation\")\n",
        "print(f\"   ğŸ“Š Meilleure adaptation au domaine des recettes\")\n",
        "\n",
        "print(f\"\\n=\" * 80)\n",
        "print(f\"ğŸ¯ NOTEBOOK FINE-TUNING COMPLET ET OPÃ‰RATIONNEL!\")\n",
        "print(f\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "itadaki_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
